{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MkDocs \u00b6 For full documentation visit mkdocs.org . Commands \u00b6 mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout \u00b6 1 2 3 4 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Intro"},{"location":"#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"#project-layout","text":"1 2 3 4 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"analysis/","text":"Real Analysis. Textbooks \u00b6 Foundations of Mathematical Analysis by Johnsonbaugh and Pfaffenberger.","title":"Intro"},{"location":"analysis/#textbooks","text":"Foundations of Mathematical Analysis by Johnsonbaugh and Pfaffenberger.","title":"Textbooks"},{"location":"analysis/countable/","text":"Completeness Axiom \u00b6 bounded \\varnothing \\neq S\\subset \\mathbb{R} \\Rightarrow \\exists \\sup \\varnothing \\neq S\\subset \\mathbb{R} \\Rightarrow \\exists \\sup . ensure no \"hole\" in real line. Lemma \u00b6 \\mathbb{N}\\times \\mathbb{N} \\mathbb{N}\\times \\mathbb{N} is countable, i.e. \\mathbb{N}\\times \\mathbb{N} \\approx \\mathbb{N} \\mathbb{N}\\times \\mathbb{N} \\approx \\mathbb{N} . Proof f(n,m) = 2^n 3^m f(n,m) = 2^n 3^m . \\square \\square Theorem \u00b6 let (A_n) (A_n) be a countable family of countable sets. Then $$ \\bigcup_{i=1}^\\infty A_i $$ is countable. Proof f(n,m) = a_n^{(m)}.\\square f(n,m) = a_n^{(m)}.\\square Corollary \u00b6 \\mathbb{Q}\\approx \\mathbb{N} \\mathbb{Q}\\approx \\mathbb{N} .","title":"Countable"},{"location":"analysis/countable/#completeness-axiom","text":"bounded \\varnothing \\neq S\\subset \\mathbb{R} \\Rightarrow \\exists \\sup \\varnothing \\neq S\\subset \\mathbb{R} \\Rightarrow \\exists \\sup . ensure no \"hole\" in real line.","title":"Completeness Axiom"},{"location":"analysis/countable/#lemma","text":"\\mathbb{N}\\times \\mathbb{N} \\mathbb{N}\\times \\mathbb{N} is countable, i.e. \\mathbb{N}\\times \\mathbb{N} \\approx \\mathbb{N} \\mathbb{N}\\times \\mathbb{N} \\approx \\mathbb{N} . Proof f(n,m) = 2^n 3^m f(n,m) = 2^n 3^m . \\square \\square","title":"Lemma"},{"location":"analysis/countable/#theorem","text":"let (A_n) (A_n) be a countable family of countable sets. Then $$ \\bigcup_{i=1}^\\infty A_i $$ is countable. Proof f(n,m) = a_n^{(m)}.\\square f(n,m) = a_n^{(m)}.\\square","title":"Theorem"},{"location":"analysis/countable/#corollary","text":"\\mathbb{Q}\\approx \\mathbb{N} \\mathbb{Q}\\approx \\mathbb{N} .","title":"Corollary"},{"location":"analysis/function/","text":"Algebra \u00b6 |f|,cf,+,-,fg,f/g |f|,cf,+,-,fg,f/g . \\lim \\lim holds. continuity holds. Continuity \u00b6 \\lim_{x\\rightarrow a} f(x) = f(a) \\lim_{x\\rightarrow a} f(x) = f(a) \\forall \\varepsilon>0,\\exists \\delta>0 \\forall \\varepsilon>0,\\exists \\delta>0 s.t. if 0<|x-a|<\\delta 0<|x-a|<\\delta then |f(x)-f(a)|<\\varepsilon |f(x)-f(a)|<\\varepsilon Theorem \u00b6 f f is continous on [a,b] [a,b] \\Rightarrow \\Rightarrow f f is bounded on [a,b] [a,b] . Theorem \u00b6 f f is continous on [a,b] [a,b] \\Rightarrow \\Rightarrow \\exists c,d\\in[a,b], \\forall x\\in[a,b], f(c)\\leq f(x) \\leq f(d) \\exists c,d\\in[a,b], \\forall x\\in[a,b], f(c)\\leq f(x) \\leq f(d) , i.e. \\exists \\exists maximum and minimum.","title":"Function"},{"location":"analysis/function/#algebra","text":"|f|,cf,+,-,fg,f/g |f|,cf,+,-,fg,f/g . \\lim \\lim holds. continuity holds.","title":"Algebra"},{"location":"analysis/function/#continuity","text":"\\lim_{x\\rightarrow a} f(x) = f(a) \\lim_{x\\rightarrow a} f(x) = f(a) \\forall \\varepsilon>0,\\exists \\delta>0 \\forall \\varepsilon>0,\\exists \\delta>0 s.t. if 0<|x-a|<\\delta 0<|x-a|<\\delta then |f(x)-f(a)|<\\varepsilon |f(x)-f(a)|<\\varepsilon","title":"Continuity"},{"location":"analysis/function/#theorem","text":"f f is continous on [a,b] [a,b] \\Rightarrow \\Rightarrow f f is bounded on [a,b] [a,b] .","title":"Theorem"},{"location":"analysis/function/#theorem_1","text":"f f is continous on [a,b] [a,b] \\Rightarrow \\Rightarrow \\exists c,d\\in[a,b], \\forall x\\in[a,b], f(c)\\leq f(x) \\leq f(d) \\exists c,d\\in[a,b], \\forall x\\in[a,b], f(c)\\leq f(x) \\leq f(d) , i.e. \\exists \\exists maximum and minimum.","title":"Theorem"},{"location":"analysis/metric/","text":"Notation \u00b6 If not specific, default on metric space (M,d) (M,d) , f:M\\rightarrow \\mathbb{R} f:M\\rightarrow \\mathbb{R} . closed: X X contain all limit points \\overline{X} \\overline{X} \\Leftrightarrow X=\\overline{X} \\Leftrightarrow X=\\overline{X} e.g. \\{x\\}, M, \\varnothing \\{x\\}, M, \\varnothing are closed. Open ball B_\\varepsilon(a):\\{x\\in M:d(x,a)<\\varepsilon\\} B_\\varepsilon(a):\\{x\\in M:d(x,a)<\\varepsilon\\} open: \\forall x\\in X \\forall x\\in X , \\exists B(x)\\subseteq X \\exists B(x)\\subseteq X e.g. M, \\varnothing M, \\varnothing are open. Definition \u00b6 A metric d:M\\times M\\rightarrow [0,\\infty) d:M\\times M\\rightarrow [0,\\infty) should satisfy d(x,y)=0 \\Leftrightarrow x=y d(x,y)=0 \\Leftrightarrow x=y d(x,y)=d(y,x), \\forall y\\in M d(x,y)=d(y,x), \\forall y\\in M d(x,y) \\leq d(x,z) + d(y,z), \\forall z\\in M d(x,y) \\leq d(x,z) + d(y,z), \\forall z\\in M e.g. (\\mathbb{R}^n,d) (\\mathbb{R}^n,d) is metric space, with d(x,y)=\\sqrt{\\sum(x-y)^2} d(x,y)=\\sqrt{\\sum(x-y)^2} Cauchy\u2013Schwarz inequality \u00b6 |\\langle u,v\\rangle| \\leq \\|u\\| \\|v\\| |\\langle u,v\\rangle| \\leq \\|u\\| \\|v\\| , equality iff u,v u,v linearly dependent. \\ell^p \\ell^p space \u00b6 set of series a a s.t. (\\sum |a|^p)^{1/p} (\\sum |a|^p)^{1/p} converge. Theorem \u00b6 a,b\\in l^2 \\Rightarrow \\sum|ab|\\rightarrow a,b\\in l^2 \\Rightarrow \\sum|ab|\\rightarrow Corollary \u00b6 a,b \\in l^2 \\Rightarrow \\sum(a-b)^2\\rightarrow \\Rightarrow \\text{metric} a,b \\in l^2 \\Rightarrow \\sum(a-b)^2\\rightarrow \\Rightarrow \\text{metric} Limit, convergence \u00b6 Definition \u00b6 \\forall \\varepsilon>0,\\exists N>0 \\forall \\varepsilon>0,\\exists N>0 s.t. if n\\geq N n\\geq N then d(a_n, L) < \\varepsilon d(a_n, L) < \\varepsilon . Theorem \u00b6 For R^n R^n , a\\rightarrow a \\Leftrightarrow a_k\\rightarrow a_k,\\forall k\\in[n] a\\rightarrow a \\Leftrightarrow a_k\\rightarrow a_k,\\forall k\\in[n] . i.e. equivalent to dimension-wise convergence. For l^1,l^2,l^\\infty,c_0 l^1,l^2,l^\\infty,c_0 , only hold \\Rightarrow \\Rightarrow . Closed and open \u00b6 Theorem \u00b6 X X open \\Leftrightarrow \\Leftrightarrow X^c X^c closed. Theorem \u00b6 \\bigcup \\bigcup of finite closeds is closed. \\bigcup [1/n,1-1/n] = (0,1) \\bigcup [1/n,1-1/n] = (0,1) \\bigcap \\bigcap of closeds is closed. Proof \u00b6 Note x\\in \\overline{\\bigcap \\mathcal{C}} x\\in \\overline{\\bigcap \\mathcal{C}} , imply x_n\\in\\bigcap \\mathcal{C},\\forall n x_n\\in\\bigcap \\mathcal{C},\\forall n . Thus x_n\\in T,\\forall n,\\forall T\\in\\mathcal{C} x_n\\in T,\\forall n,\\forall T\\in\\mathcal{C} , imply x\\in \\overline{T},\\forall T x\\in \\overline{T},\\forall T . Since T T closed, x\\in T x\\in T imply x\\in \\bigcap \\mathcal{C}.\\square x\\in \\bigcap \\mathcal{C}.\\square Theorem \u00b6 \\bigcap \\bigcap of finite opens is open. \\bigcup \\bigcup of opens is open. Continuity \u00b6 Theorem \u00b6 f f continous on compact X X \\Rightarrow \\Rightarrow f f bounded on X X . Theorem \u00b6 f f continous on compact X X \\Rightarrow \\Rightarrow \\exists \\exists maximum, minimum on X X . Uniformly continous \u00b6 \\forall \\varepsilon>0,\\exists\\delta>0 \\forall \\varepsilon>0,\\exists\\delta>0 s.t. if d_1(x,y)<\\delta d_1(x,y)<\\delta then d_2(f(x),f(y))<\\varepsilon d_2(f(x),f(y))<\\varepsilon . Cauchy Compactness \u00b6 compactness property, that is, any open cover has finite subcover. Theorems \u00b6 M M compact \\Leftrightarrow \\Leftrightarrow \\forall (a),\\exists \\forall (a),\\exists convergent subsequence. X X is compact subset of M M \\Rightarrow \\Rightarrow X X closed and bounded. X X is closed subset of compact M M \\Rightarrow \\Rightarrow X X compact. Heine\u2013Borel theorem \u00b6 For \\mathbb{R}^n \\mathbb{R}^n , S S is closed and bounded \\Leftrightarrow \\Leftrightarrow S S is compact Proof \u00b6 \\Rightarrow \\Rightarrow . Similar to B-W , assume not compact, split [l,r] [l,r] half, one of which is not compact, thus we have a infinite incompact [l_n,r_n] [l_n,r_n] , by completeness axiom, (x_n) (x_n) is picked, which is Cauchy, let the limit be L L . Note \\exists U\\in \\mathcal{C} \\exists U\\in \\mathcal{C} s.t. L\\in U L\\in U , thus \\exists B(L) \\subseteq U \\exists B(L) \\subseteq U , then for sufficiently large n, [l_n,r_n]\\subseteq B(L) \\subseteq U [l_n,r_n]\\subseteq B(L) \\subseteq U , i.e. covered by single U U , contracted to incompact assumption. \\square \\square i.e. Heine\u2013Borel \\Leftrightarrow \\Leftrightarrow Bolzano\u2013Weierstrass on \\mathbb{R}^n \\mathbb{R}^n . Theorem \u00b6 f:M_1\\rightarrow M_2 f:M_1\\rightarrow M_2 continous, compact M_1 M_1 \\Rightarrow \\Rightarrow f(M_1) f(M_1) compact \\Rightarrow \\Rightarrow f(M_1) f(M_1) closed and bounded. Theorem \u00b6 f:M_1\\rightarrow M_2 f:M_1\\rightarrow M_2 continous, compact M_1 M_1 \\Rightarrow \\Rightarrow f f uni. continous on M_1 M_1 . Corollary \u00b6 f:\\mathbb{R^n}\\rightarrow \\mathbb{{R}} f:\\mathbb{R^n}\\rightarrow \\mathbb{{R}} continous on closed and bounded X X \\Rightarrow \\Rightarrow f f uni. continous on X X . Completeness \u00b6 metric M M called complete, if \\forall \\forall Cauchy imply convergence x\\in M x\\in M . \\mathbb{R}^n, l^1,l^2,l^\\infty,c_0 \\mathbb{R}^n, l^1,l^2,l^\\infty,c_0 are complete. Theorem \u00b6 convergence x\\in M x\\in M \\Rightarrow \\Rightarrow Cauchy. Theorem \u00b6 \\forall M, \\exists \\forall M, \\exists completion, which is \\overline{M} \\overline{M} . Theorem \u00b6 compact \\Rightarrow \\Rightarrow complete. Banach fixed-point theorem \u00b6 Contracting mapping f f on complete metric \\Rightarrow \\Rightarrow \\exists \\exists unique x=f(x) x=f(x) . Proof Let x_{n+1}=f(x_n) x_{n+1}=f(x_n) with arbitrary x_0 x_0 . It's easy to verify (x_n) (x_n) is Cauchy. By completeness x\\in M x\\in M . By provable continuity that $$ f(x) = \\lim f(x_n) = \\lim x_n = x $$ Then unique followed by contracting. \\square \\square","title":"Metric"},{"location":"analysis/metric/#notation","text":"If not specific, default on metric space (M,d) (M,d) , f:M\\rightarrow \\mathbb{R} f:M\\rightarrow \\mathbb{R} . closed: X X contain all limit points \\overline{X} \\overline{X} \\Leftrightarrow X=\\overline{X} \\Leftrightarrow X=\\overline{X} e.g. \\{x\\}, M, \\varnothing \\{x\\}, M, \\varnothing are closed. Open ball B_\\varepsilon(a):\\{x\\in M:d(x,a)<\\varepsilon\\} B_\\varepsilon(a):\\{x\\in M:d(x,a)<\\varepsilon\\} open: \\forall x\\in X \\forall x\\in X , \\exists B(x)\\subseteq X \\exists B(x)\\subseteq X e.g. M, \\varnothing M, \\varnothing are open.","title":"Notation"},{"location":"analysis/metric/#definition","text":"A metric d:M\\times M\\rightarrow [0,\\infty) d:M\\times M\\rightarrow [0,\\infty) should satisfy d(x,y)=0 \\Leftrightarrow x=y d(x,y)=0 \\Leftrightarrow x=y d(x,y)=d(y,x), \\forall y\\in M d(x,y)=d(y,x), \\forall y\\in M d(x,y) \\leq d(x,z) + d(y,z), \\forall z\\in M d(x,y) \\leq d(x,z) + d(y,z), \\forall z\\in M e.g. (\\mathbb{R}^n,d) (\\mathbb{R}^n,d) is metric space, with d(x,y)=\\sqrt{\\sum(x-y)^2} d(x,y)=\\sqrt{\\sum(x-y)^2}","title":"Definition"},{"location":"analysis/metric/#cauchyschwarz-inequality","text":"|\\langle u,v\\rangle| \\leq \\|u\\| \\|v\\| |\\langle u,v\\rangle| \\leq \\|u\\| \\|v\\| , equality iff u,v u,v linearly dependent.","title":"Cauchy\u2013Schwarz inequality"},{"location":"analysis/metric/#ellpellp-space","text":"set of series a a s.t. (\\sum |a|^p)^{1/p} (\\sum |a|^p)^{1/p} converge.","title":"\\ell^p\\ell^p space"},{"location":"analysis/metric/#theorem","text":"a,b\\in l^2 \\Rightarrow \\sum|ab|\\rightarrow a,b\\in l^2 \\Rightarrow \\sum|ab|\\rightarrow","title":"Theorem"},{"location":"analysis/metric/#corollary","text":"a,b \\in l^2 \\Rightarrow \\sum(a-b)^2\\rightarrow \\Rightarrow \\text{metric} a,b \\in l^2 \\Rightarrow \\sum(a-b)^2\\rightarrow \\Rightarrow \\text{metric}","title":"Corollary"},{"location":"analysis/metric/#limit-convergence","text":"","title":"Limit, convergence"},{"location":"analysis/metric/#definition_1","text":"\\forall \\varepsilon>0,\\exists N>0 \\forall \\varepsilon>0,\\exists N>0 s.t. if n\\geq N n\\geq N then d(a_n, L) < \\varepsilon d(a_n, L) < \\varepsilon .","title":"Definition"},{"location":"analysis/metric/#theorem_1","text":"For R^n R^n , a\\rightarrow a \\Leftrightarrow a_k\\rightarrow a_k,\\forall k\\in[n] a\\rightarrow a \\Leftrightarrow a_k\\rightarrow a_k,\\forall k\\in[n] . i.e. equivalent to dimension-wise convergence. For l^1,l^2,l^\\infty,c_0 l^1,l^2,l^\\infty,c_0 , only hold \\Rightarrow \\Rightarrow .","title":"Theorem"},{"location":"analysis/metric/#closed-and-open","text":"","title":"Closed and open"},{"location":"analysis/metric/#theorem_2","text":"X X open \\Leftrightarrow \\Leftrightarrow X^c X^c closed.","title":"Theorem"},{"location":"analysis/metric/#theorem_3","text":"\\bigcup \\bigcup of finite closeds is closed. \\bigcup [1/n,1-1/n] = (0,1) \\bigcup [1/n,1-1/n] = (0,1) \\bigcap \\bigcap of closeds is closed.","title":"Theorem"},{"location":"analysis/metric/#proof","text":"Note x\\in \\overline{\\bigcap \\mathcal{C}} x\\in \\overline{\\bigcap \\mathcal{C}} , imply x_n\\in\\bigcap \\mathcal{C},\\forall n x_n\\in\\bigcap \\mathcal{C},\\forall n . Thus x_n\\in T,\\forall n,\\forall T\\in\\mathcal{C} x_n\\in T,\\forall n,\\forall T\\in\\mathcal{C} , imply x\\in \\overline{T},\\forall T x\\in \\overline{T},\\forall T . Since T T closed, x\\in T x\\in T imply x\\in \\bigcap \\mathcal{C}.\\square x\\in \\bigcap \\mathcal{C}.\\square","title":"Proof"},{"location":"analysis/metric/#theorem_4","text":"\\bigcap \\bigcap of finite opens is open. \\bigcup \\bigcup of opens is open.","title":"Theorem"},{"location":"analysis/metric/#continuity","text":"","title":"Continuity"},{"location":"analysis/metric/#theorem_5","text":"f f continous on compact X X \\Rightarrow \\Rightarrow f f bounded on X X .","title":"Theorem"},{"location":"analysis/metric/#theorem_6","text":"f f continous on compact X X \\Rightarrow \\Rightarrow \\exists \\exists maximum, minimum on X X .","title":"Theorem"},{"location":"analysis/metric/#uniformly-continous","text":"\\forall \\varepsilon>0,\\exists\\delta>0 \\forall \\varepsilon>0,\\exists\\delta>0 s.t. if d_1(x,y)<\\delta d_1(x,y)<\\delta then d_2(f(x),f(y))<\\varepsilon d_2(f(x),f(y))<\\varepsilon . Cauchy","title":"Uniformly continous"},{"location":"analysis/metric/#compactness","text":"compactness property, that is, any open cover has finite subcover.","title":"Compactness"},{"location":"analysis/metric/#theorems","text":"M M compact \\Leftrightarrow \\Leftrightarrow \\forall (a),\\exists \\forall (a),\\exists convergent subsequence. X X is compact subset of M M \\Rightarrow \\Rightarrow X X closed and bounded. X X is closed subset of compact M M \\Rightarrow \\Rightarrow X X compact.","title":"Theorems"},{"location":"analysis/metric/#heineborel-theorem","text":"For \\mathbb{R}^n \\mathbb{R}^n , S S is closed and bounded \\Leftrightarrow \\Leftrightarrow S S is compact","title":"Heine\u2013Borel theorem"},{"location":"analysis/metric/#proof_1","text":"\\Rightarrow \\Rightarrow . Similar to B-W , assume not compact, split [l,r] [l,r] half, one of which is not compact, thus we have a infinite incompact [l_n,r_n] [l_n,r_n] , by completeness axiom, (x_n) (x_n) is picked, which is Cauchy, let the limit be L L . Note \\exists U\\in \\mathcal{C} \\exists U\\in \\mathcal{C} s.t. L\\in U L\\in U , thus \\exists B(L) \\subseteq U \\exists B(L) \\subseteq U , then for sufficiently large n, [l_n,r_n]\\subseteq B(L) \\subseteq U [l_n,r_n]\\subseteq B(L) \\subseteq U , i.e. covered by single U U , contracted to incompact assumption. \\square \\square i.e. Heine\u2013Borel \\Leftrightarrow \\Leftrightarrow Bolzano\u2013Weierstrass on \\mathbb{R}^n \\mathbb{R}^n .","title":"Proof"},{"location":"analysis/metric/#theorem_7","text":"f:M_1\\rightarrow M_2 f:M_1\\rightarrow M_2 continous, compact M_1 M_1 \\Rightarrow \\Rightarrow f(M_1) f(M_1) compact \\Rightarrow \\Rightarrow f(M_1) f(M_1) closed and bounded.","title":"Theorem"},{"location":"analysis/metric/#theorem_8","text":"f:M_1\\rightarrow M_2 f:M_1\\rightarrow M_2 continous, compact M_1 M_1 \\Rightarrow \\Rightarrow f f uni. continous on M_1 M_1 .","title":"Theorem"},{"location":"analysis/metric/#corollary_1","text":"f:\\mathbb{R^n}\\rightarrow \\mathbb{{R}} f:\\mathbb{R^n}\\rightarrow \\mathbb{{R}} continous on closed and bounded X X \\Rightarrow \\Rightarrow f f uni. continous on X X .","title":"Corollary"},{"location":"analysis/metric/#completeness","text":"metric M M called complete, if \\forall \\forall Cauchy imply convergence x\\in M x\\in M . \\mathbb{R}^n, l^1,l^2,l^\\infty,c_0 \\mathbb{R}^n, l^1,l^2,l^\\infty,c_0 are complete.","title":"Completeness"},{"location":"analysis/metric/#theorem_9","text":"convergence x\\in M x\\in M \\Rightarrow \\Rightarrow Cauchy.","title":"Theorem"},{"location":"analysis/metric/#theorem_10","text":"\\forall M, \\exists \\forall M, \\exists completion, which is \\overline{M} \\overline{M} .","title":"Theorem"},{"location":"analysis/metric/#theorem_11","text":"compact \\Rightarrow \\Rightarrow complete.","title":"Theorem"},{"location":"analysis/metric/#banach-fixed-point-theorem","text":"Contracting mapping f f on complete metric \\Rightarrow \\Rightarrow \\exists \\exists unique x=f(x) x=f(x) . Proof Let x_{n+1}=f(x_n) x_{n+1}=f(x_n) with arbitrary x_0 x_0 . It's easy to verify (x_n) (x_n) is Cauchy. By completeness x\\in M x\\in M . By provable continuity that $$ f(x) = \\lim f(x_n) = \\lim x_n = x $$ Then unique followed by contracting. \\square \\square","title":"Banach fixed-point theorem"},{"location":"analysis/sequence/","text":"Limit \u00b6 Definition \u00b6 (a_n) (a_n) has limit L\\in \\mathbb{{R}} L\\in \\mathbb{{R}} : \\forall \\varepsilon>0, \\exists N>0 \\forall \\varepsilon>0, \\exists N>0 s.t. if n\\geq N n\\geq N , then |a_n - L| < \\varepsilon |a_n - L| < \\varepsilon . Theorem \u00b6 (a_n) (a_n) has limit L L , then any subsequence (a_{f(n)}) (a_{f(n)}) has same limit L L . Proof f(n)\\geq f(N) \\geq N.\\square f(n)\\geq f(N) \\geq N.\\square Algebra \u00b6 Let $$ \\lim_{n\\rightarrow\\infty}a_n=L,\\lim_{n\\rightarrow\\infty}b_n=M $$ that \\begin{align} \\lim_{n\\rightarrow\\infty} (a_n + b_n) &= L + M \\\\ \\lim_{n\\rightarrow\\infty} ca_n &= cL \\\\ \\lim_{n\\rightarrow\\infty} (a_n - b_n) &= L - M \\\\ \\lim_{n\\rightarrow\\infty} a_n b_n &= L M \\\\ M \\neq 0 \\Rightarrow \\lim_{n\\rightarrow\\infty} a_n / b_n &= L / M \\\\ \\end{align} Bounded \u00b6 Definition \u00b6 \\forall n, a_n \\leq M \\forall n, a_n \\leq M . Theorem \u00b6 convergent \\Rightarrow \\Rightarrow bounded. monotone, then convergent \\Leftrightarrow \\Leftrightarrow bounded. Theorem \u00b6 (a_n) (a_n) is bounded, and (b_n) (b_n) limits 0, then (a_nb_n) (a_nb_n) limits 0. Proof |b_n| < \\varepsilon / M.\\square |b_n| < \\varepsilon / M.\\square Squeeze \u00b6 Theorem \u00b6 \\forall n, a_n\\leq b_n\\leq c_n \\forall n, a_n\\leq b_n\\leq c_n . If (a_n),(c_n) (a_n),(c_n) limits L L , then (b_n) (b_n) limits L L . Definition \u00b6 diverge to infinity: \\forall M, \\exists N > 0 \\forall M, \\exists N > 0 , s.t. if n\\geq N n\\geq N then a_n>M a_n>M . Theorem \u00b6 \\forall n, a_n\\leq b_n \\forall n, a_n\\leq b_n , if (a_n) (a_n) diverge to \\infty \\infty , then (b_n) (b_n) diverge to \\infty \\infty . Real Exponents \u00b6 a^x = \\lim a^{r_n} a^x = \\lim a^{r_n} is well defined. Bolzano\u2013Weierstrass theorem \u00b6 bounded \\Rightarrow \\exists \\Rightarrow \\exists convergent subsequence. Proof bounded, i.e. a_n \\in [l,r] a_n \\in [l,r] , take a_{n_1} a_{n_1} from which. Note one of [l,\\frac{l+r}{2}] [l,\\frac{l+r}{2}] and [\\frac{l+r}{2},r] [\\frac{l+r}{2},r] has a_n a_n infinitely many times. Thus we can take n_2>n_1 n_2>n_1 from which, keep this procedure. (l_n), (r_n) (l_n), (r_n) both monotone thus convergent, and (r_n-l_n) (r_n-l_n) limits 0. By sequeeze, (a_{n_i}) (a_{n_i}) converge. \\square \\square Cauchy Condition \u00b6 \\forall \\varepsilon>0, \\exists N>0 \\forall \\varepsilon>0, \\exists N>0 s.t. if m,n\\geq N m,n\\geq N , then |a_m-a_n|<\\varepsilon |a_m-a_n|<\\varepsilon . Theorem \u00b6 convergent \\Leftrightarrow \\Leftrightarrow Cauchy. Proof \\Rightarrow \\Rightarrow . take radius \\varepsilon/2 \\varepsilon/2 of limit, thus |a_m-a_n|<\\varepsilon |a_m-a_n|<\\varepsilon . \\Leftarrow \\Leftarrow . let \\varepsilon=1 \\varepsilon=1 , thus (a_n) (a_n) is bounded by \\max{|a_1|,\\cdots, |a_{N-1}|, 1+|a_{N}|} \\max{|a_1|,\\cdots, |a_{N-1}|, 1+|a_{N}|} . By B-W , (a_{n_i}) (a_{n_i}) converge to some L L . Then take (N,\\varepsilon/2) (N,\\varepsilon/2) of Cauchy, and (N_2,\\varepsilon/2) (N_2,\\varepsilon/2) of convergent (a_{n_i}) (a_{n_i}) . Choose K\\geq N_2 K\\geq N_2 and n_K \\geq N n_K \\geq N , thus if n\\geq N n\\geq N $$ |a_n-L| \\leq |a_n - a_{n_K}| + |a_{n_K} - L| < \\varepsilon/2 + \\varepsilon/2 = \\varepsilon $$ \\square \\square lim sup \u00b6 Definition \u00b6 \\limsup a_n= \\limsup a_n= \\lim_{n\\rightarrow\\infty} \\sup_{m\\geq n} a_m \\lim_{n\\rightarrow\\infty} \\sup_{m\\geq n} a_m \\inf_{n\\geq 1} \\sup_{m\\geq n} a_m \\inf_{n\\geq 1} \\sup_{m\\geq n} a_m \\sup E \\sup E , where E E is set of limit points of convergent subsequence of (a_n) (a_n) . Limit of \"tail boarder\". Theorem \u00b6 (a_n),(b_n) (a_n),(b_n) are bounded, then $$ \\liminf a_n + \\liminf b_n \\leq \\liminf(a_n+b_n), \\limsup(a_n+b_n) \\leq \\limsup a_n + \\limsup b_n $$ Proof Note \\forall n > 0 \\forall n > 0 $$ \\inf_{m\\geq n} a_m \\leq a_k \\leq \\sup_{m\\geq n} a_m, \\forall k\\geq n $$ thus $$ \\inf_{\\geq n} a + \\inf_{\\geq n} b \\leq a_k + b_k \\leq \\sup_{\\geq n} a + \\sup_{\\geq n} b, \\forall k\\geq n $$ take \\inf \\inf or \\sup \\sup on middle to get \\begin{align} \\inf_{\\geq n} a + \\inf_{\\geq n} b \\leq \\inf_{\\geq n} (a+b) \\\\ \\sup_{\\geq n} (a+b) \\leq \\sup_{\\geq n} a + \\sup_{\\geq n} b \\end{align} as n\\rightarrow\\infty.\\square n\\rightarrow\\infty.\\square For any tail, each point under \"tail boarder\", thus sum of two still under.","title":"Sequence"},{"location":"analysis/sequence/#limit","text":"","title":"Limit"},{"location":"analysis/sequence/#definition","text":"(a_n) (a_n) has limit L\\in \\mathbb{{R}} L\\in \\mathbb{{R}} : \\forall \\varepsilon>0, \\exists N>0 \\forall \\varepsilon>0, \\exists N>0 s.t. if n\\geq N n\\geq N , then |a_n - L| < \\varepsilon |a_n - L| < \\varepsilon .","title":"Definition"},{"location":"analysis/sequence/#theorem","text":"(a_n) (a_n) has limit L L , then any subsequence (a_{f(n)}) (a_{f(n)}) has same limit L L . Proof f(n)\\geq f(N) \\geq N.\\square f(n)\\geq f(N) \\geq N.\\square","title":"Theorem"},{"location":"analysis/sequence/#algebra","text":"Let $$ \\lim_{n\\rightarrow\\infty}a_n=L,\\lim_{n\\rightarrow\\infty}b_n=M $$ that \\begin{align} \\lim_{n\\rightarrow\\infty} (a_n + b_n) &= L + M \\\\ \\lim_{n\\rightarrow\\infty} ca_n &= cL \\\\ \\lim_{n\\rightarrow\\infty} (a_n - b_n) &= L - M \\\\ \\lim_{n\\rightarrow\\infty} a_n b_n &= L M \\\\ M \\neq 0 \\Rightarrow \\lim_{n\\rightarrow\\infty} a_n / b_n &= L / M \\\\ \\end{align}","title":"Algebra"},{"location":"analysis/sequence/#bounded","text":"","title":"Bounded"},{"location":"analysis/sequence/#definition_1","text":"\\forall n, a_n \\leq M \\forall n, a_n \\leq M .","title":"Definition"},{"location":"analysis/sequence/#theorem_1","text":"convergent \\Rightarrow \\Rightarrow bounded. monotone, then convergent \\Leftrightarrow \\Leftrightarrow bounded.","title":"Theorem"},{"location":"analysis/sequence/#theorem_2","text":"(a_n) (a_n) is bounded, and (b_n) (b_n) limits 0, then (a_nb_n) (a_nb_n) limits 0. Proof |b_n| < \\varepsilon / M.\\square |b_n| < \\varepsilon / M.\\square","title":"Theorem"},{"location":"analysis/sequence/#squeeze","text":"","title":"Squeeze"},{"location":"analysis/sequence/#theorem_3","text":"\\forall n, a_n\\leq b_n\\leq c_n \\forall n, a_n\\leq b_n\\leq c_n . If (a_n),(c_n) (a_n),(c_n) limits L L , then (b_n) (b_n) limits L L .","title":"Theorem"},{"location":"analysis/sequence/#definition_2","text":"diverge to infinity: \\forall M, \\exists N > 0 \\forall M, \\exists N > 0 , s.t. if n\\geq N n\\geq N then a_n>M a_n>M .","title":"Definition"},{"location":"analysis/sequence/#theorem_4","text":"\\forall n, a_n\\leq b_n \\forall n, a_n\\leq b_n , if (a_n) (a_n) diverge to \\infty \\infty , then (b_n) (b_n) diverge to \\infty \\infty .","title":"Theorem"},{"location":"analysis/sequence/#real-exponents","text":"a^x = \\lim a^{r_n} a^x = \\lim a^{r_n} is well defined.","title":"Real Exponents"},{"location":"analysis/sequence/#bolzanoweierstrass-theorem","text":"bounded \\Rightarrow \\exists \\Rightarrow \\exists convergent subsequence. Proof bounded, i.e. a_n \\in [l,r] a_n \\in [l,r] , take a_{n_1} a_{n_1} from which. Note one of [l,\\frac{l+r}{2}] [l,\\frac{l+r}{2}] and [\\frac{l+r}{2},r] [\\frac{l+r}{2},r] has a_n a_n infinitely many times. Thus we can take n_2>n_1 n_2>n_1 from which, keep this procedure. (l_n), (r_n) (l_n), (r_n) both monotone thus convergent, and (r_n-l_n) (r_n-l_n) limits 0. By sequeeze, (a_{n_i}) (a_{n_i}) converge. \\square \\square","title":"Bolzano\u2013Weierstrass theorem"},{"location":"analysis/sequence/#cauchy-condition","text":"\\forall \\varepsilon>0, \\exists N>0 \\forall \\varepsilon>0, \\exists N>0 s.t. if m,n\\geq N m,n\\geq N , then |a_m-a_n|<\\varepsilon |a_m-a_n|<\\varepsilon .","title":"Cauchy Condition"},{"location":"analysis/sequence/#theorem_5","text":"convergent \\Leftrightarrow \\Leftrightarrow Cauchy. Proof \\Rightarrow \\Rightarrow . take radius \\varepsilon/2 \\varepsilon/2 of limit, thus |a_m-a_n|<\\varepsilon |a_m-a_n|<\\varepsilon . \\Leftarrow \\Leftarrow . let \\varepsilon=1 \\varepsilon=1 , thus (a_n) (a_n) is bounded by \\max{|a_1|,\\cdots, |a_{N-1}|, 1+|a_{N}|} \\max{|a_1|,\\cdots, |a_{N-1}|, 1+|a_{N}|} . By B-W , (a_{n_i}) (a_{n_i}) converge to some L L . Then take (N,\\varepsilon/2) (N,\\varepsilon/2) of Cauchy, and (N_2,\\varepsilon/2) (N_2,\\varepsilon/2) of convergent (a_{n_i}) (a_{n_i}) . Choose K\\geq N_2 K\\geq N_2 and n_K \\geq N n_K \\geq N , thus if n\\geq N n\\geq N $$ |a_n-L| \\leq |a_n - a_{n_K}| + |a_{n_K} - L| < \\varepsilon/2 + \\varepsilon/2 = \\varepsilon $$ \\square \\square","title":"Theorem"},{"location":"analysis/sequence/#lim-sup","text":"","title":"lim sup"},{"location":"analysis/sequence/#definition_3","text":"\\limsup a_n= \\limsup a_n= \\lim_{n\\rightarrow\\infty} \\sup_{m\\geq n} a_m \\lim_{n\\rightarrow\\infty} \\sup_{m\\geq n} a_m \\inf_{n\\geq 1} \\sup_{m\\geq n} a_m \\inf_{n\\geq 1} \\sup_{m\\geq n} a_m \\sup E \\sup E , where E E is set of limit points of convergent subsequence of (a_n) (a_n) . Limit of \"tail boarder\".","title":"Definition"},{"location":"analysis/sequence/#theorem_6","text":"(a_n),(b_n) (a_n),(b_n) are bounded, then $$ \\liminf a_n + \\liminf b_n \\leq \\liminf(a_n+b_n), \\limsup(a_n+b_n) \\leq \\limsup a_n + \\limsup b_n $$ Proof Note \\forall n > 0 \\forall n > 0 $$ \\inf_{m\\geq n} a_m \\leq a_k \\leq \\sup_{m\\geq n} a_m, \\forall k\\geq n $$ thus $$ \\inf_{\\geq n} a + \\inf_{\\geq n} b \\leq a_k + b_k \\leq \\sup_{\\geq n} a + \\sup_{\\geq n} b, \\forall k\\geq n $$ take \\inf \\inf or \\sup \\sup on middle to get \\begin{align} \\inf_{\\geq n} a + \\inf_{\\geq n} b \\leq \\inf_{\\geq n} (a+b) \\\\ \\sup_{\\geq n} (a+b) \\leq \\sup_{\\geq n} a + \\sup_{\\geq n} b \\end{align} as n\\rightarrow\\infty.\\square n\\rightarrow\\infty.\\square For any tail, each point under \"tail boarder\", thus sum of two still under.","title":"Theorem"},{"location":"analysis/series/","text":"Notation \u00b6 $$ s_n = \\sum_{i=1}^n a_n \\\\ a\\rightarrow L:\\lim_{n\\rightarrow\\infty}a_n=L \\\\ a:\\forall n, a_n $$ i.e. comprehensive notation. Algebra \u00b6 +,-,cs +,-,cs hold. Convergence Tests \u00b6 s\\rightarrow \\Rightarrow a\\rightarrow0 \\\\\\\\ a\\geq 0: s\\rightarrow \\Leftrightarrow s \\text{ bounded} s\\rightarrow \\Rightarrow a\\rightarrow0 \\\\\\\\ a\\geq 0: s\\rightarrow \\Leftrightarrow s \\text{ bounded} 2^n 2^n Cauchy condensation test \u00b6 a\\geq 0, a\\searrow: s\\rightarrow \\Leftrightarrow \\sum 2^na_{2^n}\\rightarrow a\\geq 0, a\\searrow: s\\rightarrow \\Leftrightarrow \\sum 2^na_{2^n}\\rightarrow Alternating series test \u00b6 a\\searrow, a\\rightarrow 0 \\Rightarrow \\sum(-1)^na_n\\rightarrow a\\searrow, a\\rightarrow 0 \\Rightarrow \\sum(-1)^na_n\\rightarrow Comparison test \u00b6 If for sufficiently large n n , |a_n|\\leq C|b_n| |a_n|\\leq C|b_n| $$ \\sum|b|\\rightarrow \\Rightarrow \\sum|a|\\rightarrow $$ Ratio test \u00b6 \\left|\\dfrac{a_n+1}{a_n}\\right|\\rightarrow L, \\begin{cases}L<1\\Rightarrow \\sum|a|\\rightarrow \\\\\\\\ L>1 \\Rightarrow s \\not\\rightarrow \\end{cases} \\left|\\dfrac{a_n+1}{a_n}\\right|\\rightarrow L, \\begin{cases}L<1\\Rightarrow \\sum|a|\\rightarrow \\\\\\\\ L>1 \\Rightarrow s \\not\\rightarrow \\end{cases} Root test \u00b6 L=\\limsup |a_n|^{1/n}, \\begin{cases}L<1\\Rightarrow \\sum|a|\\rightarrow \\\\\\\\ L>1 \\Rightarrow s \\not\\rightarrow \\end{cases} L=\\limsup |a_n|^{1/n}, \\begin{cases}L<1\\Rightarrow \\sum|a|\\rightarrow \\\\\\\\ L>1 \\Rightarrow s \\not\\rightarrow \\end{cases} Binary \u00b6 Theorem \u00b6 \\sum |a|\\rightarrow, b \\text{ bounded} \\Rightarrow \\sum |ab|\\rightarrow \\\\\\\\ \\sum |a|\\not\\rightarrow,1/b \\text{ bounded} \\Rightarrow \\sum|ab| \\not\\rightarrow \\sum |a|\\rightarrow, b \\text{ bounded} \\Rightarrow \\sum |ab|\\rightarrow \\\\\\\\ \\sum |a|\\not\\rightarrow,1/b \\text{ bounded} \\Rightarrow \\sum|ab| \\not\\rightarrow Lemma \u00b6 \\sum_{i=1}^n a_ib_i = s_nb_{n+1} + \\sum_{i=1}^n s_i(b_i - b_{i+1}) \\sum_{i=1}^n a_ib_i = s_nb_{n+1} + \\sum_{i=1}^n s_i(b_i - b_{i+1}) Theorem \u00b6 \\sum a \\text{ bounded}, \\sum|b_{n+1}-b_n|\\rightarrow, b\\rightarrow 0 \\Rightarrow \\sum ab\\rightarrow \\sum a \\text{ bounded}, \\sum|b_{n+1}-b_n|\\rightarrow, b\\rightarrow 0 \\Rightarrow \\sum ab\\rightarrow Dirichlet test \u00b6 \\sum a \\text{ bounded}, b\\searrow,b\\rightarrow 0 \\Rightarrow \\sum ab\\rightarrow \\sum a \\text{ bounded}, b\\searrow,b\\rightarrow 0 \\Rightarrow \\sum ab\\rightarrow Theorem \u00b6 \\sum a\\rightarrow, \\sum |b_n - b_{n+1}|\\rightarrow \\Rightarrow \\sum ab\\rightarrow \\sum a\\rightarrow, \\sum |b_n - b_{n+1}|\\rightarrow \\Rightarrow \\sum ab\\rightarrow Abel test \u00b6 \\sum a\\rightarrow, b\\text{ bounded monotone} \\Rightarrow \\sum ab\\rightarrow \\sum a\\rightarrow, b\\text{ bounded monotone} \\Rightarrow \\sum ab\\rightarrow Power series \u00b6 let L = \\limsup |a_n|^{1/n} L = \\limsup |a_n|^{1/n} , the radius of \\sum a_n(x-t)^n \\sum a_n(x-t)^n is 1/L 1/L . Double series \u00b6 Definition \u00b6 sum by rows exist: \\sum_n a_{m,n}\\rightarrow \\sum_n a_{m,n}\\rightarrow and \\sum_m(\\sum_n a_{m,n})\\rightarrow \\sum_m(\\sum_n a_{m,n})\\rightarrow . Lemma \u00b6 a\\geq 0 a\\geq 0 : sum by row exist \\Leftrightarrow \\Leftrightarrow sum by column exist, and equal. Theorem \u00b6 \\sum_{m,n}|a|\\rightarrow \\Rightarrow \\sum_m\\sum_na=\\sum_n\\sum_ma\\rightarrow, \\sum_m|\\sum_n a|\\rightarrow, \\sum_n|\\sum_m a|\\rightarrow \\sum_{m,n}|a|\\rightarrow \\Rightarrow \\sum_m\\sum_na=\\sum_n\\sum_ma\\rightarrow, \\sum_m|\\sum_n a|\\rightarrow, \\sum_n|\\sum_m a|\\rightarrow Permutation \u00b6 \\sum_n |a_n|\\rightarrow \\Rightarrow \\sum_{p(n)}|a_n|\\rightarrow, \\sum_{p(n)}a=\\sum_n a \\sum_n |a_n|\\rightarrow \\Rightarrow \\sum_{p(n)}|a_n|\\rightarrow, \\sum_{p(n)}a=\\sum_n a Cauchy product \u00b6 \\sum|a|\\rightarrow, \\sum|b|\\rightarrow \\Rightarrow \\sum |c|\\rightarrow, \\sum c=\\sum a \\sum b \\sum|a|\\rightarrow, \\sum|b|\\rightarrow \\Rightarrow \\sum |c|\\rightarrow, \\sum c=\\sum a \\sum b","title":"Series"},{"location":"analysis/series/#notation","text":"$$ s_n = \\sum_{i=1}^n a_n \\\\ a\\rightarrow L:\\lim_{n\\rightarrow\\infty}a_n=L \\\\ a:\\forall n, a_n $$ i.e. comprehensive notation.","title":"Notation"},{"location":"analysis/series/#algebra","text":"+,-,cs +,-,cs hold.","title":"Algebra"},{"location":"analysis/series/#convergence-tests","text":"s\\rightarrow \\Rightarrow a\\rightarrow0 \\\\\\\\ a\\geq 0: s\\rightarrow \\Leftrightarrow s \\text{ bounded} s\\rightarrow \\Rightarrow a\\rightarrow0 \\\\\\\\ a\\geq 0: s\\rightarrow \\Leftrightarrow s \\text{ bounded}","title":"Convergence Tests"},{"location":"analysis/series/#2n2n-cauchy-condensation-test","text":"a\\geq 0, a\\searrow: s\\rightarrow \\Leftrightarrow \\sum 2^na_{2^n}\\rightarrow a\\geq 0, a\\searrow: s\\rightarrow \\Leftrightarrow \\sum 2^na_{2^n}\\rightarrow","title":"2^n2^n Cauchy condensation test"},{"location":"analysis/series/#alternating-series-test","text":"a\\searrow, a\\rightarrow 0 \\Rightarrow \\sum(-1)^na_n\\rightarrow a\\searrow, a\\rightarrow 0 \\Rightarrow \\sum(-1)^na_n\\rightarrow","title":"Alternating series test"},{"location":"analysis/series/#comparison-test","text":"If for sufficiently large n n , |a_n|\\leq C|b_n| |a_n|\\leq C|b_n| $$ \\sum|b|\\rightarrow \\Rightarrow \\sum|a|\\rightarrow $$","title":"Comparison test"},{"location":"analysis/series/#ratio-test","text":"\\left|\\dfrac{a_n+1}{a_n}\\right|\\rightarrow L, \\begin{cases}L<1\\Rightarrow \\sum|a|\\rightarrow \\\\\\\\ L>1 \\Rightarrow s \\not\\rightarrow \\end{cases} \\left|\\dfrac{a_n+1}{a_n}\\right|\\rightarrow L, \\begin{cases}L<1\\Rightarrow \\sum|a|\\rightarrow \\\\\\\\ L>1 \\Rightarrow s \\not\\rightarrow \\end{cases}","title":"Ratio test"},{"location":"analysis/series/#root-test","text":"L=\\limsup |a_n|^{1/n}, \\begin{cases}L<1\\Rightarrow \\sum|a|\\rightarrow \\\\\\\\ L>1 \\Rightarrow s \\not\\rightarrow \\end{cases} L=\\limsup |a_n|^{1/n}, \\begin{cases}L<1\\Rightarrow \\sum|a|\\rightarrow \\\\\\\\ L>1 \\Rightarrow s \\not\\rightarrow \\end{cases}","title":"Root test"},{"location":"analysis/series/#binary","text":"","title":"Binary"},{"location":"analysis/series/#theorem","text":"\\sum |a|\\rightarrow, b \\text{ bounded} \\Rightarrow \\sum |ab|\\rightarrow \\\\\\\\ \\sum |a|\\not\\rightarrow,1/b \\text{ bounded} \\Rightarrow \\sum|ab| \\not\\rightarrow \\sum |a|\\rightarrow, b \\text{ bounded} \\Rightarrow \\sum |ab|\\rightarrow \\\\\\\\ \\sum |a|\\not\\rightarrow,1/b \\text{ bounded} \\Rightarrow \\sum|ab| \\not\\rightarrow","title":"Theorem"},{"location":"analysis/series/#lemma","text":"\\sum_{i=1}^n a_ib_i = s_nb_{n+1} + \\sum_{i=1}^n s_i(b_i - b_{i+1}) \\sum_{i=1}^n a_ib_i = s_nb_{n+1} + \\sum_{i=1}^n s_i(b_i - b_{i+1})","title":"Lemma"},{"location":"analysis/series/#theorem_1","text":"\\sum a \\text{ bounded}, \\sum|b_{n+1}-b_n|\\rightarrow, b\\rightarrow 0 \\Rightarrow \\sum ab\\rightarrow \\sum a \\text{ bounded}, \\sum|b_{n+1}-b_n|\\rightarrow, b\\rightarrow 0 \\Rightarrow \\sum ab\\rightarrow","title":"Theorem"},{"location":"analysis/series/#dirichlet-test","text":"\\sum a \\text{ bounded}, b\\searrow,b\\rightarrow 0 \\Rightarrow \\sum ab\\rightarrow \\sum a \\text{ bounded}, b\\searrow,b\\rightarrow 0 \\Rightarrow \\sum ab\\rightarrow","title":"Dirichlet test"},{"location":"analysis/series/#theorem_2","text":"\\sum a\\rightarrow, \\sum |b_n - b_{n+1}|\\rightarrow \\Rightarrow \\sum ab\\rightarrow \\sum a\\rightarrow, \\sum |b_n - b_{n+1}|\\rightarrow \\Rightarrow \\sum ab\\rightarrow","title":"Theorem"},{"location":"analysis/series/#abel-test","text":"\\sum a\\rightarrow, b\\text{ bounded monotone} \\Rightarrow \\sum ab\\rightarrow \\sum a\\rightarrow, b\\text{ bounded monotone} \\Rightarrow \\sum ab\\rightarrow","title":"Abel test"},{"location":"analysis/series/#power-series","text":"let L = \\limsup |a_n|^{1/n} L = \\limsup |a_n|^{1/n} , the radius of \\sum a_n(x-t)^n \\sum a_n(x-t)^n is 1/L 1/L .","title":"Power series"},{"location":"analysis/series/#double-series","text":"","title":"Double series"},{"location":"analysis/series/#definition","text":"sum by rows exist: \\sum_n a_{m,n}\\rightarrow \\sum_n a_{m,n}\\rightarrow and \\sum_m(\\sum_n a_{m,n})\\rightarrow \\sum_m(\\sum_n a_{m,n})\\rightarrow .","title":"Definition"},{"location":"analysis/series/#lemma_1","text":"a\\geq 0 a\\geq 0 : sum by row exist \\Leftrightarrow \\Leftrightarrow sum by column exist, and equal.","title":"Lemma"},{"location":"analysis/series/#theorem_3","text":"\\sum_{m,n}|a|\\rightarrow \\Rightarrow \\sum_m\\sum_na=\\sum_n\\sum_ma\\rightarrow, \\sum_m|\\sum_n a|\\rightarrow, \\sum_n|\\sum_m a|\\rightarrow \\sum_{m,n}|a|\\rightarrow \\Rightarrow \\sum_m\\sum_na=\\sum_n\\sum_ma\\rightarrow, \\sum_m|\\sum_n a|\\rightarrow, \\sum_n|\\sum_m a|\\rightarrow","title":"Theorem"},{"location":"analysis/series/#permutation","text":"\\sum_n |a_n|\\rightarrow \\Rightarrow \\sum_{p(n)}|a_n|\\rightarrow, \\sum_{p(n)}a=\\sum_n a \\sum_n |a_n|\\rightarrow \\Rightarrow \\sum_{p(n)}|a_n|\\rightarrow, \\sum_{p(n)}a=\\sum_n a","title":"Permutation"},{"location":"analysis/series/#cauchy-product","text":"\\sum|a|\\rightarrow, \\sum|b|\\rightarrow \\Rightarrow \\sum |c|\\rightarrow, \\sum c=\\sum a \\sum b \\sum|a|\\rightarrow, \\sum|b|\\rightarrow \\Rightarrow \\sum |c|\\rightarrow, \\sum c=\\sum a \\sum b","title":"Cauchy product"},{"location":"measure/","text":"Textbooks \u00b6 Amir Dembo's notes. Cheat sheets \u00b6 classic Notations \u00b6 space \u00b6 sample space: \\Omega \\Omega power set: 2^\\Omega 2^\\Omega event space, or \\sigma \\sigma -algebra: \\mathcal{F}\\subseteq 2^\\Omega \\mathcal{F}\\subseteq 2^\\Omega measure: \\mu \\mu - Lebesgue: \\lambda \\lambda coutable union: \\bigcup_i \\bigcup_i possibly uncountable unoin: \\bigcup, \\bigcup_\\alpha \\bigcup, \\bigcup_\\alpha measureable space: (\\Omega,\\mathcal{F}) (\\Omega,\\mathcal{F}) measure space: (\\Omega,\\mathcal{F},\\mu) (\\Omega,\\mathcal{F},\\mu) probability space: (\\Omega,\\mathcal{F},P) (\\Omega,\\mathcal{F},P) limit \u00b6 A_i\\uparrow A: A_1\\subseteq A_2\\subseteq\\cdots,\\bigcup_i A_i=A A_i\\uparrow A: A_1\\subseteq A_2\\subseteq\\cdots,\\bigcup_i A_i=A . A_i\\downarrow A: A_1\\supseteq A_2\\supseteq\\cdots,\\bigcap_i A_i=A A_i\\downarrow A: A_1\\supseteq A_2\\supseteq\\cdots,\\bigcap_i A_i=A . generated \\sigma \\sigma \u00b6 By algebra: \\sigma(\\mathcal{A}) \\sigma(\\mathcal{A}) By R.V.: \\mathcal{F}^X = \\sigma(X) \\mathcal{F}^X = \\sigma(X) By R.V.s: \\mathcal{F}_n^X = \\sigma (X_1,\\cdots,X_n) \\mathcal{F}_n^X = \\sigma (X_1,\\cdots,X_n) Tail of stochastic process \\{X_k\\} \\{X_k\\} : \\mathcal{T}_n^X = \\sigma (X_t, t>n) \\mathcal{T}_n^X = \\sigma (X_t, t>n) \\mathcal{T}^X = \\bigcap_n \\mathcal{T}_n^X \\mathcal{T}^X = \\bigcap_n \\mathcal{T}_n^X abbr \u00b6 SF: simple function \\sum_i^n c_i I_i \\sum_i^n c_i I_i R.V.: random variable. a.s.: almost sure a.e.: almost everywhere w.p.1: with probability 1 m.zero: measure zero m.indep.: mutually independent S.P.: stochastic process i.i.d.: independent and identically distributed LLD: law of large numbers CLT: central limit theorem i.o.: infinitely often ev.: eventually limsup \u00b6 \\limsup A_n = \\inf_{n\\geq 1} \\sup_{i\\geq n} A_i = \\bigcap_n\\bigcup_{i\\geq n} A_i = \\{A_n\\ i.o.\\} \\\\\\\\ \\liminf A_n = \\sup_{n\\geq 1} \\inf_{i\\geq n} A_i = \\bigcup_n\\bigcap_{i\\geq n} A_i = \\{A_n\\ ev.\\} \\\\\\\\ \\limsup A_n = \\inf_{n\\geq 1} \\sup_{i\\geq n} A_i = \\bigcap_n\\bigcup_{i\\geq n} A_i = \\{A_n\\ i.o.\\} \\\\\\\\ \\liminf A_n = \\sup_{n\\geq 1} \\inf_{i\\geq n} A_i = \\bigcup_n\\bigcap_{i\\geq n} A_i = \\{A_n\\ ev.\\} \\\\\\\\ occur infinitely, or occur all after some large n. Models \u00b6 RW: random walk SRW: simple random walk sym-SRM: symmetric SRM","title":"Intro"},{"location":"measure/#textbooks","text":"Amir Dembo's notes.","title":"Textbooks"},{"location":"measure/#cheat-sheets","text":"classic","title":"Cheat sheets"},{"location":"measure/#notations","text":"","title":"Notations"},{"location":"measure/#space","text":"sample space: \\Omega \\Omega power set: 2^\\Omega 2^\\Omega event space, or \\sigma \\sigma -algebra: \\mathcal{F}\\subseteq 2^\\Omega \\mathcal{F}\\subseteq 2^\\Omega measure: \\mu \\mu - Lebesgue: \\lambda \\lambda coutable union: \\bigcup_i \\bigcup_i possibly uncountable unoin: \\bigcup, \\bigcup_\\alpha \\bigcup, \\bigcup_\\alpha measureable space: (\\Omega,\\mathcal{F}) (\\Omega,\\mathcal{F}) measure space: (\\Omega,\\mathcal{F},\\mu) (\\Omega,\\mathcal{F},\\mu) probability space: (\\Omega,\\mathcal{F},P) (\\Omega,\\mathcal{F},P)","title":"space"},{"location":"measure/#limit","text":"A_i\\uparrow A: A_1\\subseteq A_2\\subseteq\\cdots,\\bigcup_i A_i=A A_i\\uparrow A: A_1\\subseteq A_2\\subseteq\\cdots,\\bigcup_i A_i=A . A_i\\downarrow A: A_1\\supseteq A_2\\supseteq\\cdots,\\bigcap_i A_i=A A_i\\downarrow A: A_1\\supseteq A_2\\supseteq\\cdots,\\bigcap_i A_i=A .","title":"limit"},{"location":"measure/#generated-sigmasigma","text":"By algebra: \\sigma(\\mathcal{A}) \\sigma(\\mathcal{A}) By R.V.: \\mathcal{F}^X = \\sigma(X) \\mathcal{F}^X = \\sigma(X) By R.V.s: \\mathcal{F}_n^X = \\sigma (X_1,\\cdots,X_n) \\mathcal{F}_n^X = \\sigma (X_1,\\cdots,X_n) Tail of stochastic process \\{X_k\\} \\{X_k\\} : \\mathcal{T}_n^X = \\sigma (X_t, t>n) \\mathcal{T}_n^X = \\sigma (X_t, t>n) \\mathcal{T}^X = \\bigcap_n \\mathcal{T}_n^X \\mathcal{T}^X = \\bigcap_n \\mathcal{T}_n^X","title":"generated \\sigma\\sigma"},{"location":"measure/#abbr","text":"SF: simple function \\sum_i^n c_i I_i \\sum_i^n c_i I_i R.V.: random variable. a.s.: almost sure a.e.: almost everywhere w.p.1: with probability 1 m.zero: measure zero m.indep.: mutually independent S.P.: stochastic process i.i.d.: independent and identically distributed LLD: law of large numbers CLT: central limit theorem i.o.: infinitely often ev.: eventually","title":"abbr"},{"location":"measure/#limsup","text":"\\limsup A_n = \\inf_{n\\geq 1} \\sup_{i\\geq n} A_i = \\bigcap_n\\bigcup_{i\\geq n} A_i = \\{A_n\\ i.o.\\} \\\\\\\\ \\liminf A_n = \\sup_{n\\geq 1} \\inf_{i\\geq n} A_i = \\bigcup_n\\bigcap_{i\\geq n} A_i = \\{A_n\\ ev.\\} \\\\\\\\ \\limsup A_n = \\inf_{n\\geq 1} \\sup_{i\\geq n} A_i = \\bigcap_n\\bigcup_{i\\geq n} A_i = \\{A_n\\ i.o.\\} \\\\\\\\ \\liminf A_n = \\sup_{n\\geq 1} \\inf_{i\\geq n} A_i = \\bigcup_n\\bigcap_{i\\geq n} A_i = \\{A_n\\ ev.\\} \\\\\\\\ occur infinitely, or occur all after some large n.","title":"limsup"},{"location":"measure/#models","text":"RW: random walk SRW: simple random walk sym-SRM: symmetric SRM","title":"Models"},{"location":"measure/ce/","text":"Comprehensive notes, omit some condition, and maybe incorrect. Radon-Nikodym theorem \u00b6 \u4e24\u4e2a\u6d4b\u5ea6\u7684\u76f8\u5bf9\u53d8\u5316\u7387\uff08\u6c42\u5bfc\uff09\uff0c\u552f\u4e00(a.s.) mutually singular \u00b6 \u4e24\u4e2a\u6d4b\u5ea6\u88ab\u67d0\u4e2aA\u5212\u5206\uff0c\u5373 \\mu_1(A)=0, \\mu_2(A^c)=0 \\mu_1(A)=0, \\mu_2(A^c)=0 Lebesgue decomposition \u00b6 \u4e00\u4e2a\u6d4b\u5ea6\u53ef\u4ee5\u552f\u4e00\u5206\u89e3\u4e3a\u53e6\u4e00\u6d4b\u5ea6\u7684\u5782\u76f4\uff0c\u548c\u5bfc v=fu+u_\\perp v=fu+u_\\perp . Properties of C.E. \u00b6 Omit many. Basic properties from wiki.","title":"Conditional expectation"},{"location":"measure/ce/#radon-nikodym-theorem","text":"\u4e24\u4e2a\u6d4b\u5ea6\u7684\u76f8\u5bf9\u53d8\u5316\u7387\uff08\u6c42\u5bfc\uff09\uff0c\u552f\u4e00(a.s.)","title":"Radon-Nikodym theorem"},{"location":"measure/ce/#mutually-singular","text":"\u4e24\u4e2a\u6d4b\u5ea6\u88ab\u67d0\u4e2aA\u5212\u5206\uff0c\u5373 \\mu_1(A)=0, \\mu_2(A^c)=0 \\mu_1(A)=0, \\mu_2(A^c)=0","title":"mutually singular"},{"location":"measure/ce/#lebesgue-decomposition","text":"\u4e00\u4e2a\u6d4b\u5ea6\u53ef\u4ee5\u552f\u4e00\u5206\u89e3\u4e3a\u53e6\u4e00\u6d4b\u5ea6\u7684\u5782\u76f4\uff0c\u548c\u5bfc v=fu+u_\\perp v=fu+u_\\perp .","title":"Lebesgue decomposition"},{"location":"measure/ce/#properties-of-ce","text":"Omit many. Basic properties from wiki.","title":"Properties of C.E."},{"location":"measure/cf/","text":"CF \u00b6 Levy continuity theorem \u00b6 Poisson \u00b6","title":"Characteristic function"},{"location":"measure/cf/#cf","text":"","title":"CF"},{"location":"measure/cf/#levy-continuity-theorem","text":"","title":"Levy continuity theorem"},{"location":"measure/cf/#poisson","text":"","title":"Poisson"},{"location":"measure/clt/","text":"Convergence in distribution \u00b6 \\lim F_n(x)=F(x),\\forall x \\lim F_n(x)=F(x),\\forall x CLT \u00b6 i.i.d. \\sigma^2<\\infty \\sigma^2<\\infty , then $$ \\dfrac{\\sum^nX_n - n\\mu}{\\sqrt{n\\sigma^2}}\\xrightarrow{d}\\mathcal{N}(0,1)=G \\\\ \\sqrt{n}(\\overline{X}_n-\\mu) \\xrightarrow{d}\\mathcal{N}(0,\\sigma^2) $$ Lindeberg CLT \u00b6 moment be restricted. P-m.indep. \\mu_n=0,s_n^2=\\sum\\sigma^2\\rightarrow1 \\mu_n=0,s_n^2=\\sum\\sigma^2\\rightarrow1 , if \\forall \\varepsilon>0 \\forall \\varepsilon>0 , s_n^{-2} \\sum^nE[X_i^2I_{|X_i|>\\varepsilon}]\\rightarrow 0 s_n^{-2} \\sum^nE[X_i^2I_{|X_i|>\\varepsilon}]\\rightarrow 0 , then \\dfrac{\\sum^nX_n}{s_n},\\sum^nX_n\\xrightarrow{d}G \\dfrac{\\sum^nX_n}{s_n},\\sum^nX_n\\xrightarrow{d}G Lyapunov CLT \u00b6 P-m.indep. \\mu_n=0,s_n^2=\\sum\\sigma^2\\rightarrow1 \\mu_n=0,s_n^2=\\sum\\sigma^2\\rightarrow1 , if \\exists\\delta>0 \\exists\\delta>0 , s_n^{-2-\\delta}\\sum^nE[|X_i|^{2+\\delta}]\\rightarrow0 s_n^{-2-\\delta}\\sum^nE[|X_i|^{2+\\delta}]\\rightarrow0 , then \\dfrac{\\sum^nX_n}{s_n},\\sum^nX_n\\xrightarrow{d}G \\dfrac{\\sum^nX_n}{s_n},\\sum^nX_n\\xrightarrow{d}G","title":"Central limit theorem"},{"location":"measure/clt/#convergence-in-distribution","text":"\\lim F_n(x)=F(x),\\forall x \\lim F_n(x)=F(x),\\forall x","title":"Convergence in distribution"},{"location":"measure/clt/#clt","text":"i.i.d. \\sigma^2<\\infty \\sigma^2<\\infty , then $$ \\dfrac{\\sum^nX_n - n\\mu}{\\sqrt{n\\sigma^2}}\\xrightarrow{d}\\mathcal{N}(0,1)=G \\\\ \\sqrt{n}(\\overline{X}_n-\\mu) \\xrightarrow{d}\\mathcal{N}(0,\\sigma^2) $$","title":"CLT"},{"location":"measure/clt/#lindeberg-clt","text":"moment be restricted. P-m.indep. \\mu_n=0,s_n^2=\\sum\\sigma^2\\rightarrow1 \\mu_n=0,s_n^2=\\sum\\sigma^2\\rightarrow1 , if \\forall \\varepsilon>0 \\forall \\varepsilon>0 , s_n^{-2} \\sum^nE[X_i^2I_{|X_i|>\\varepsilon}]\\rightarrow 0 s_n^{-2} \\sum^nE[X_i^2I_{|X_i|>\\varepsilon}]\\rightarrow 0 , then \\dfrac{\\sum^nX_n}{s_n},\\sum^nX_n\\xrightarrow{d}G \\dfrac{\\sum^nX_n}{s_n},\\sum^nX_n\\xrightarrow{d}G","title":"Lindeberg CLT"},{"location":"measure/clt/#lyapunov-clt","text":"P-m.indep. \\mu_n=0,s_n^2=\\sum\\sigma^2\\rightarrow1 \\mu_n=0,s_n^2=\\sum\\sigma^2\\rightarrow1 , if \\exists\\delta>0 \\exists\\delta>0 , s_n^{-2-\\delta}\\sum^nE[|X_i|^{2+\\delta}]\\rightarrow0 s_n^{-2-\\delta}\\sum^nE[|X_i|^{2+\\delta}]\\rightarrow0 , then \\dfrac{\\sum^nX_n}{s_n},\\sum^nX_n\\xrightarrow{d}G \\dfrac{\\sum^nX_n}{s_n},\\sum^nX_n\\xrightarrow{d}G","title":"Lyapunov CLT"},{"location":"measure/inequal/","text":"Markov \u00b6 classic \u00b6 For X\\geq 0, a>0 X\\geq 0, a>0 P(X\\geq a) \\leq \\dfrac{EX}{a} P(X\\geq a) \\leq \\dfrac{EX}{a} value, bounded by expectation measure \u00b6 Wiki for meaure and extended. Chebyshev \u00b6 classic \u00b6 For X\\in L^2, a>0 X\\in L^2, a>0 P(|X-EX|\\geq a^2) \\leq \\dfrac{\\text{Var}(X)}{a^2} P(|X-EX|\\geq a^2) \\leq \\dfrac{\\text{Var}(X)}{a^2} bias, bounded by variance Jensen \u00b6 For convex f f f(ax+(1-a)y) \\leq af(x)+(1-a)f(y) f(ax+(1-a)y) \\leq af(x)+(1-a)f(y) classic \u00b6 f(EX) \\leq Ef(X) f(EX) \\leq Ef(X) H\u00f6lder \u00b6 p,q \\geq 1 p,q \\geq 1 , \\frac{1}{p} +\\frac{1}{q}=1 \\frac{1}{p} +\\frac{1}{q}=1 E|XY|=\\|XY\\|_1\\leq \\|X\\|_p \\|Y\\|_q E|XY|=\\|XY\\|_1\\leq \\|X\\|_p \\|Y\\|_q (p,q) (p,q) called H\u00f6lder conjugates. (2,2) (2,2) imply Cauchy\u2013Schwarz. Minkowski \u00b6 X,Y\\in L^p,p\\geq 1 X,Y\\in L^p,p\\geq 1 \\|X+Y\\|_p \\leq \\|X\\|_p + \\|Y\\|_p \\|X+Y\\|_p \\leq \\|X\\|_p + \\|Y\\|_p triangle in L^p L^p Kolmogorov's maximal \u00b6 P-m.indep. X_n=0,EX_n^2<\\infty,a>0 X_n=0,EX_n^2<\\infty,a>0 , then P(\\max_{1\\leq k\\leq n}|S_k|\\geq a) \\leq a^{-2}\\text{Var}(S_n)=a^{-2}\\sum^n EX_i^2 P(\\max_{1\\leq k\\leq n}|S_k|\\geq a) \\leq a^{-2}\\text{Var}(S_n)=a^{-2}\\sum^n EX_i^2 max of abs partial sum, bounded by variance Doob's martingale \u00b6 sub-MG, a>0 a>0 , $$ P(\\max_{0\\leq k\\leq n}X_k \\geq a) \\leq a^{-1}E[(X_n)_+] $$ max of past, bounded by latest positived expectation. Generalized Kolmogorov's maximal. L^p L^p maximal \u00b6 p>1 p>1 , \\|\\max_{k\\leq n}X_k\\|_p \\leq \\dfrac{p}{p-1}\\|X_n\\|_p \\\\\\\\ E[\\max_{k\\leq n}X_k] \\leq \\dfrac{e}{e-1}(1 + E[X_n(\\log X_n)_+]) \\|\\max_{k\\leq n}X_k\\|_p \\leq \\dfrac{p}{p-1}\\|X_n\\|_p \\\\\\\\ E[\\max_{k\\leq n}X_k] \\leq \\dfrac{e}{e-1}(1 + E[X_n(\\log X_n)_+]) Doob's up-crossing \u00b6 sup-MG, a<b a<b (b-a)E[U_n[a,b]] \\leq E(X_n-a)_- - E(X_0-a)_- (b-a)E[U_n[a,b]] \\leq E(X_n-a)_- - E(X_0-a)_- up-crossing of losing S.P., bounded by latest. Dubins' up-crossing \u00b6 sup-MG X_n\\geq 0 X_n\\geq 0 , 0<a<b 0<a<b , P(U_\\infty\\geq l)\\leq \\left(\\dfrac{a}{b}\\right)^l E[\\min(X_0/a, 1)] P(U_\\infty\\geq l)\\leq \\left(\\dfrac{a}{b}\\right)^l E[\\min(X_0/a, 1)] total up-crossing of losing S.P., bounded by X_0/a, a/b X_0/a, a/b .","title":"Inequalities"},{"location":"measure/inequal/#markov","text":"","title":"Markov"},{"location":"measure/inequal/#classic","text":"For X\\geq 0, a>0 X\\geq 0, a>0 P(X\\geq a) \\leq \\dfrac{EX}{a} P(X\\geq a) \\leq \\dfrac{EX}{a} value, bounded by expectation","title":"classic"},{"location":"measure/inequal/#measure","text":"Wiki for meaure and extended.","title":"measure"},{"location":"measure/inequal/#chebyshev","text":"","title":"Chebyshev"},{"location":"measure/inequal/#classic_1","text":"For X\\in L^2, a>0 X\\in L^2, a>0 P(|X-EX|\\geq a^2) \\leq \\dfrac{\\text{Var}(X)}{a^2} P(|X-EX|\\geq a^2) \\leq \\dfrac{\\text{Var}(X)}{a^2} bias, bounded by variance","title":"classic"},{"location":"measure/inequal/#jensen","text":"For convex f f f(ax+(1-a)y) \\leq af(x)+(1-a)f(y) f(ax+(1-a)y) \\leq af(x)+(1-a)f(y)","title":"Jensen"},{"location":"measure/inequal/#classic_2","text":"f(EX) \\leq Ef(X) f(EX) \\leq Ef(X)","title":"classic"},{"location":"measure/inequal/#holder","text":"p,q \\geq 1 p,q \\geq 1 , \\frac{1}{p} +\\frac{1}{q}=1 \\frac{1}{p} +\\frac{1}{q}=1 E|XY|=\\|XY\\|_1\\leq \\|X\\|_p \\|Y\\|_q E|XY|=\\|XY\\|_1\\leq \\|X\\|_p \\|Y\\|_q (p,q) (p,q) called H\u00f6lder conjugates. (2,2) (2,2) imply Cauchy\u2013Schwarz.","title":"H\u00f6lder"},{"location":"measure/inequal/#minkowski","text":"X,Y\\in L^p,p\\geq 1 X,Y\\in L^p,p\\geq 1 \\|X+Y\\|_p \\leq \\|X\\|_p + \\|Y\\|_p \\|X+Y\\|_p \\leq \\|X\\|_p + \\|Y\\|_p triangle in L^p L^p","title":"Minkowski"},{"location":"measure/inequal/#kolmogorovs-maximal","text":"P-m.indep. X_n=0,EX_n^2<\\infty,a>0 X_n=0,EX_n^2<\\infty,a>0 , then P(\\max_{1\\leq k\\leq n}|S_k|\\geq a) \\leq a^{-2}\\text{Var}(S_n)=a^{-2}\\sum^n EX_i^2 P(\\max_{1\\leq k\\leq n}|S_k|\\geq a) \\leq a^{-2}\\text{Var}(S_n)=a^{-2}\\sum^n EX_i^2 max of abs partial sum, bounded by variance","title":"Kolmogorov's maximal"},{"location":"measure/inequal/#doobs-martingale","text":"sub-MG, a>0 a>0 , $$ P(\\max_{0\\leq k\\leq n}X_k \\geq a) \\leq a^{-1}E[(X_n)_+] $$ max of past, bounded by latest positived expectation. Generalized Kolmogorov's maximal.","title":"Doob's martingale"},{"location":"measure/inequal/#lplp-maximal","text":"p>1 p>1 , \\|\\max_{k\\leq n}X_k\\|_p \\leq \\dfrac{p}{p-1}\\|X_n\\|_p \\\\\\\\ E[\\max_{k\\leq n}X_k] \\leq \\dfrac{e}{e-1}(1 + E[X_n(\\log X_n)_+]) \\|\\max_{k\\leq n}X_k\\|_p \\leq \\dfrac{p}{p-1}\\|X_n\\|_p \\\\\\\\ E[\\max_{k\\leq n}X_k] \\leq \\dfrac{e}{e-1}(1 + E[X_n(\\log X_n)_+])","title":"L^pL^p maximal"},{"location":"measure/inequal/#doobs-up-crossing","text":"sup-MG, a<b a<b (b-a)E[U_n[a,b]] \\leq E(X_n-a)_- - E(X_0-a)_- (b-a)E[U_n[a,b]] \\leq E(X_n-a)_- - E(X_0-a)_- up-crossing of losing S.P., bounded by latest.","title":"Doob's up-crossing"},{"location":"measure/inequal/#dubins-up-crossing","text":"sup-MG X_n\\geq 0 X_n\\geq 0 , 0<a<b 0<a<b , P(U_\\infty\\geq l)\\leq \\left(\\dfrac{a}{b}\\right)^l E[\\min(X_0/a, 1)] P(U_\\infty\\geq l)\\leq \\left(\\dfrac{a}{b}\\right)^l E[\\min(X_0/a, 1)] total up-crossing of losing S.P., bounded by X_0/a, a/b X_0/a, a/b .","title":"Dubins' up-crossing"},{"location":"measure/lln/","text":"L^2 L^2 Weak LLD \u00b6 Uncorrelated X_i X_i , \\text{Var}(X_i)<\\infty, EX_i=\\mu <\\infty \\text{Var}(X_i)<\\infty, EX_i=\\mu <\\infty , then \\overline{X}_n \\xrightarrow{L^2} \\mu \\overline{X}_n \\xrightarrow{L^2} \\mu , hence \\overline{X}_n \\xrightarrow{p} \\mu \\overline{X}_n \\xrightarrow{p} \\mu Proof \u00b6 \\text{Var}(\\overline{X}_n)\\leq \\dfrac{\\sum^n C}{n^2} = \\dfrac{C}{n}\\rightarrow 0 \\text{Var}(\\overline{X}_n)\\leq \\dfrac{\\sum^n C}{n^2} = \\dfrac{C}{n}\\rightarrow 0 Coupon collector\u2019s problem \u00b6 ET_n = n H_n, \\dfrac{T_n}{n\\log n}\\xrightarrow{L^2} 1 ET_n = n H_n, \\dfrac{T_n}{n\\log n}\\xrightarrow{L^2} 1 infinite coupons \u00b6 let D_n D_n denote collected in first n n . $$ D_n\\xrightarrow{a.s.}\\infty, n^{-1}D_n\\xrightarrow{p}0 $$ Occupacy problem \u00b6 r r bolls to n n boxes, with \\dfrac{r}{n}\\rightarrow\\alpha\\in[0,\\infty] \\dfrac{r}{n}\\rightarrow\\alpha\\in[0,\\infty] , the emptyness n^{-1}N_n\\xrightarrow{L^2,p} e^{-\\alpha} n^{-1}N_n\\xrightarrow{L^2,p} e^{-\\alpha} Weak triangular \u00b6 For bounded on some slow b_n b_n . Weak LLN \u00b6 i.i.d., xP(|X_1|>x)\\rightarrow 0 xP(|X_1|>x)\\rightarrow 0 , then \\overline{X}_n\\xrightarrow{p}\\mu_n=E[X_1I_{|X_1|\\leq n}] \\overline{X}_n\\xrightarrow{p}\\mu_n=E[X_1I_{|X_1|\\leq n}] classic \u00b6 i.i.d., E|X_1|<\\infty E|X_1|<\\infty , then \\overline{X}_n\\xrightarrow{p}\\mu \\overline{X}_n\\xrightarrow{p}\\mu Borel-Cantelli \u00b6 I \u00b6 \\sum_i P(A_i) < \\infty \\sum_i P(A_i) < \\infty , then P(A_n\\ i.o.)=0 P(A_n\\ i.o.)=0 . II \u00b6 P-m.indep. \\sum_iP(A_i)=\\infty \\sum_iP(A_i)=\\infty , then P(A_n\\ i.o.)=1 P(A_n\\ i.o.)=1 . Collorary 0-1 law \u00b6 P-m.indep., then \\{A_n\\ i.o.\\} \\{A_n\\ i.o.\\} is P-trivial. Strong LLN \u00b6 pairwise-i.i.d., either EX_+ EX_+ or EX_- EX_- finite, then $$ \\overline{X}_n \\xrightarrow{a.s.} \\mu $$","title":"Law of large numbers"},{"location":"measure/lln/#l2l2-weak-lld","text":"Uncorrelated X_i X_i , \\text{Var}(X_i)<\\infty, EX_i=\\mu <\\infty \\text{Var}(X_i)<\\infty, EX_i=\\mu <\\infty , then \\overline{X}_n \\xrightarrow{L^2} \\mu \\overline{X}_n \\xrightarrow{L^2} \\mu , hence \\overline{X}_n \\xrightarrow{p} \\mu \\overline{X}_n \\xrightarrow{p} \\mu","title":"L^2L^2 Weak LLD"},{"location":"measure/lln/#proof","text":"\\text{Var}(\\overline{X}_n)\\leq \\dfrac{\\sum^n C}{n^2} = \\dfrac{C}{n}\\rightarrow 0 \\text{Var}(\\overline{X}_n)\\leq \\dfrac{\\sum^n C}{n^2} = \\dfrac{C}{n}\\rightarrow 0","title":"Proof"},{"location":"measure/lln/#coupon-collectors-problem","text":"ET_n = n H_n, \\dfrac{T_n}{n\\log n}\\xrightarrow{L^2} 1 ET_n = n H_n, \\dfrac{T_n}{n\\log n}\\xrightarrow{L^2} 1","title":"Coupon collector\u2019s problem"},{"location":"measure/lln/#infinite-coupons","text":"let D_n D_n denote collected in first n n . $$ D_n\\xrightarrow{a.s.}\\infty, n^{-1}D_n\\xrightarrow{p}0 $$","title":"infinite coupons"},{"location":"measure/lln/#occupacy-problem","text":"r r bolls to n n boxes, with \\dfrac{r}{n}\\rightarrow\\alpha\\in[0,\\infty] \\dfrac{r}{n}\\rightarrow\\alpha\\in[0,\\infty] , the emptyness n^{-1}N_n\\xrightarrow{L^2,p} e^{-\\alpha} n^{-1}N_n\\xrightarrow{L^2,p} e^{-\\alpha}","title":"Occupacy problem"},{"location":"measure/lln/#weak-triangular","text":"For bounded on some slow b_n b_n .","title":"Weak triangular"},{"location":"measure/lln/#weak-lln","text":"i.i.d., xP(|X_1|>x)\\rightarrow 0 xP(|X_1|>x)\\rightarrow 0 , then \\overline{X}_n\\xrightarrow{p}\\mu_n=E[X_1I_{|X_1|\\leq n}] \\overline{X}_n\\xrightarrow{p}\\mu_n=E[X_1I_{|X_1|\\leq n}]","title":"Weak LLN"},{"location":"measure/lln/#classic","text":"i.i.d., E|X_1|<\\infty E|X_1|<\\infty , then \\overline{X}_n\\xrightarrow{p}\\mu \\overline{X}_n\\xrightarrow{p}\\mu","title":"classic"},{"location":"measure/lln/#borel-cantelli","text":"","title":"Borel-Cantelli"},{"location":"measure/lln/#i","text":"\\sum_i P(A_i) < \\infty \\sum_i P(A_i) < \\infty , then P(A_n\\ i.o.)=0 P(A_n\\ i.o.)=0 .","title":"I"},{"location":"measure/lln/#ii","text":"P-m.indep. \\sum_iP(A_i)=\\infty \\sum_iP(A_i)=\\infty , then P(A_n\\ i.o.)=1 P(A_n\\ i.o.)=1 .","title":"II"},{"location":"measure/lln/#collorary-0-1-law","text":"P-m.indep., then \\{A_n\\ i.o.\\} \\{A_n\\ i.o.\\} is P-trivial.","title":"Collorary 0-1 law"},{"location":"measure/lln/#strong-lln","text":"pairwise-i.i.d., either EX_+ EX_+ or EX_- EX_- finite, then $$ \\overline{X}_n \\xrightarrow{a.s.} \\mu $$","title":"Strong LLN"},{"location":"measure/markov/","text":"Markov property \u00b6 P(X_{n+1}\\in A|F_n) = P(X_{n+1}\\in A|X_n), \\forall n, a.s. P(X_{n+1}\\in A|F_n) = P(X_{n+1}\\in A|X_n), \\forall n, a.s. i.e. memoryless, only based on current state. Strong Markov property \u00b6 Hold for X_{\\tau} X_{\\tau} , \\tau<\\infty \\tau<\\infty . Chapman-Kolmogorov \u00b6 transition, equal to countable convolution on some middle state. Definitions \u00b6 accessible \u00b6 \\rho_{xy}:=P_x(T_y<\\infty) > 0 \\rho_{xy}:=P_x(T_y<\\infty) > 0 . i.e. x x leads to y y . intercommunicate \u00b6 both accessible, x\\leftrightarrow y x\\leftrightarrow y . irreducible \u00b6 Any two intercommunicate. closed \u00b6 Won't transition out. recurrent(persistent) \u00b6 \\rho_{xx}=1 \\rho_{xx}=1 . equivalents, 6.2.12 transient \u00b6 \\rho_{xx} < 1 \\rho_{xx} < 1 . Proposition 6.2.10 \u00b6 Let T_y^k T_y^k be k-th return, then P_x(T_y^k < \\infty) = \\rho_{xy}\\rho_{yy}^{k-1} \\\\\\\\ E_x[N_{\\infty}(y)] = \\dfrac{\\rho_{xy}}{1 - \\rho_{yy}} P_x(T_y^k < \\infty) = \\rho_{xy}\\rho_{yy}^{k-1} \\\\\\\\ E_x[N_{\\infty}(y)] = \\dfrac{\\rho_{xy}}{1 - \\rho_{yy}} Decomposition theorem \u00b6 S = T \\cup R_1\\cup R_2\\cup \\cdots S = T \\cup R_1\\cup R_2\\cup \\cdots one transient, other ireducible. invariant measure \u00b6 default for transition p p . \\mu(y) = \\sum_x \\mu(x)p(x,y) \\mu(y) = \\sum_x \\mu(x)p(x,y) classic \u00b6 \\pi = \\pi P \\pi = \\pi P Proposition 6.2.41. \u00b6 \\pi(z) = 1/E_z[T_z] \\pi(z) = 1/E_z[T_z] . Convergence Theorem 6.2.59 \u00b6 Thermodynamics equilibrium.","title":"Markov chain"},{"location":"measure/markov/#markov-property","text":"P(X_{n+1}\\in A|F_n) = P(X_{n+1}\\in A|X_n), \\forall n, a.s. P(X_{n+1}\\in A|F_n) = P(X_{n+1}\\in A|X_n), \\forall n, a.s. i.e. memoryless, only based on current state.","title":"Markov property"},{"location":"measure/markov/#strong-markov-property","text":"Hold for X_{\\tau} X_{\\tau} , \\tau<\\infty \\tau<\\infty .","title":"Strong Markov property"},{"location":"measure/markov/#chapman-kolmogorov","text":"transition, equal to countable convolution on some middle state.","title":"Chapman-Kolmogorov"},{"location":"measure/markov/#definitions","text":"","title":"Definitions"},{"location":"measure/markov/#accessible","text":"\\rho_{xy}:=P_x(T_y<\\infty) > 0 \\rho_{xy}:=P_x(T_y<\\infty) > 0 . i.e. x x leads to y y .","title":"accessible"},{"location":"measure/markov/#intercommunicate","text":"both accessible, x\\leftrightarrow y x\\leftrightarrow y .","title":"intercommunicate"},{"location":"measure/markov/#irreducible","text":"Any two intercommunicate.","title":"irreducible"},{"location":"measure/markov/#closed","text":"Won't transition out.","title":"closed"},{"location":"measure/markov/#recurrentpersistent","text":"\\rho_{xx}=1 \\rho_{xx}=1 . equivalents, 6.2.12","title":"recurrent(persistent)"},{"location":"measure/markov/#transient","text":"\\rho_{xx} < 1 \\rho_{xx} < 1 .","title":"transient"},{"location":"measure/markov/#proposition-6210","text":"Let T_y^k T_y^k be k-th return, then P_x(T_y^k < \\infty) = \\rho_{xy}\\rho_{yy}^{k-1} \\\\\\\\ E_x[N_{\\infty}(y)] = \\dfrac{\\rho_{xy}}{1 - \\rho_{yy}} P_x(T_y^k < \\infty) = \\rho_{xy}\\rho_{yy}^{k-1} \\\\\\\\ E_x[N_{\\infty}(y)] = \\dfrac{\\rho_{xy}}{1 - \\rho_{yy}}","title":"Proposition 6.2.10"},{"location":"measure/markov/#decomposition-theorem","text":"S = T \\cup R_1\\cup R_2\\cup \\cdots S = T \\cup R_1\\cup R_2\\cup \\cdots one transient, other ireducible.","title":"Decomposition theorem"},{"location":"measure/markov/#invariant-measure","text":"default for transition p p . \\mu(y) = \\sum_x \\mu(x)p(x,y) \\mu(y) = \\sum_x \\mu(x)p(x,y)","title":"invariant measure"},{"location":"measure/markov/#classic","text":"\\pi = \\pi P \\pi = \\pi P","title":"classic"},{"location":"measure/markov/#proposition-6241","text":"\\pi(z) = 1/E_z[T_z] \\pi(z) = 1/E_z[T_z] .","title":"Proposition 6.2.41."},{"location":"measure/markov/#convergence-theorem-6259","text":"Thermodynamics equilibrium.","title":"Convergence Theorem 6.2.59"},{"location":"measure/mf/","text":"Definition \u00b6 Mapping between two measurable spaces (\\Omega, \\mathcal{F}), (\\mathbb{S},\\mathcal{S}) (\\Omega, \\mathcal{F}), (\\mathbb{S},\\mathcal{S}) , also called measurable mapping, Borel function f f , random variable(R.V.) X X , if \\forall B\\in \\mathcal{S} \\forall B\\in \\mathcal{S} X^{-1}(B):= \\{A:X(A)\\in B\\} \\in\\mathcal{F} X^{-1}(B):= \\{A:X(A)\\in B\\} \\in\\mathcal{F} i.e. contain preimage. Convergence \u00b6 Theorem \u00b6 \\rightarrow\\overline{\\mathbb{R}}, f_n\\in mF \\Rightarrow \\sup_n f_n,\\inf_n f_n, \\limsup_{n\\rightarrow\\infty}f_n,\\liminf f_n \\in mF \\rightarrow\\overline{\\mathbb{R}}, f_n\\in mF \\Rightarrow \\sup_n f_n,\\inf_n f_n, \\limsup_{n\\rightarrow\\infty}f_n,\\liminf f_n \\in mF Theorem \u00b6 For any sequence f_n f_n \\Omega_0:=\\{ \\omega:\\liminf f = \\limsup f \\} \\\\\\\\ \\Omega_1:=\\{ \\omega:\\liminf f = \\limsup f \\in \\mathbb{R}\\} \\Omega_0:=\\{ \\omega:\\liminf f = \\limsup f \\} \\\\\\\\ \\Omega_1:=\\{ \\omega:\\liminf f = \\limsup f \\in \\mathbb{R}\\} are measurable, i.e. \\Omega_0,\\Omega_1 \\in F \\Omega_0,\\Omega_1 \\in F . set converge to \\infty \\infty or finite limit. Type of convergence \u00b6 pointwise convergence: f_n(\\omega)\\rightarrow f(\\omega) f_n(\\omega)\\rightarrow f(\\omega) . a.s. convergence: f_n \\xrightarrow{a.s.}f f_n \\xrightarrow{a.s.}f , P(\\Omega_0) P(\\Omega_0) w.p.1. P(X_n\\rightarrow X)=1 P(X_n\\rightarrow X)=1 a.s. convergence to finite limit: P(\\Omega_1) P(\\Omega_1) w.p.1. convergence in probability: f_n \\xrightarrow{p}f f_n \\xrightarrow{p}f \\forall \\varepsilon>0 \\forall \\varepsilon>0 , P(x:|f_n(x)-f(x)|>\\varepsilon)\\rightarrow 0 P(x:|f_n(x)-f(x)|>\\varepsilon)\\rightarrow 0 . convergence in L^p L^p : f_n\\xrightarrow{L^p}f f_n\\xrightarrow{L^p}f f_n,f\\in L^p f_n,f\\in L^p , \\|f_n-f\\|_p\\rightarrow 0 \\|f_n-f\\|_p\\rightarrow 0 . (a.e.) pointwise is strong; a.s. means eventually, P(\\lim) P(\\lim) ; in probability, \\lim(P) \\lim(P) . Relationship \u00b6 \\begin{align} \\xrightarrow{a.s.} &\\Rightarrow \\xrightarrow{p} \\\\\\\\ \\xrightarrow{L^p},p\\geq r &\\Rightarrow \\xrightarrow{L^r} \\\\\\\\ \\xrightarrow{L^p} &\\Rightarrow \\xrightarrow{p} \\end{align} \\begin{align} \\xrightarrow{a.s.} &\\Rightarrow \\xrightarrow{p} \\\\\\\\ \\xrightarrow{L^p},p\\geq r &\\Rightarrow \\xrightarrow{L^r} \\\\\\\\ \\xrightarrow{L^p} &\\Rightarrow \\xrightarrow{p} \\end{align} More properties on wiki . Monotone convergence theorem \u00b6 f_n\\geq 0 f_n\\geq 0 pointwise converge, then \\mu(f_n)\\uparrow \\mu(f)\\leq \\infty \\mu(f_n)\\uparrow \\mu(f)\\leq \\infty . general \u00b6 f_n\\geq 0 f_n\\geq 0 , f_n\\uparrow f f_n\\uparrow f a.e., then Ef_n\\uparrow Ef Ef_n\\uparrow Ef . Fatou's lemma \u00b6 bridge \\limsup,\\liminf \\limsup,\\liminf on a.s. measure sense. Dominated convergence theorem \u00b6 Scheffe's lemma \u00b6 U.I. \u00b6 Vitali's convergence theorem \u00b6 Standard machine \u00b6 Steps to prove some property hold h\\in L^1 h\\in L^1 . prove indicator. by linearity, extent to SF_+ SF_+ by MON thm, extent to mF_+ mF_+ h=h_+-h_- h=h_+-h_- , extent to L^1 L^1 Definition \u00b6 distribution \u00b6 F:\\mathbb{R}\\rightarrow [0,1] F:\\mathbb{R}\\rightarrow [0,1] is distribution of some R.V. iff \\nearrow \\nearrow . imply a.s. differentiable. \\lim_{x\\rightarrow\\infty} F(x)=1 \\lim_{x\\rightarrow\\infty} F(x)=1 and \\lim_{x\\rightarrow -\\infty} F(x)= 0 \\lim_{x\\rightarrow -\\infty} F(x)= 0 right-continous: \\lim_{x\\downarrow a}F(x)=F(a) \\lim_{x\\downarrow a}F(x)=F(a) pdf \u00b6 F_X(x)=\\int_{-\\infty}^xf_X(t)dt, \\forall x\\in \\mathbb{R} F_X(x)=\\int_{-\\infty}^xf_X(t)dt, \\forall x\\in \\mathbb{R} P-trivial \u00b6 either P(A)=0 P(A)=0 or P(A^c)=0 P(A^c)=0 . expectation \u00b6 E[X]=\\int XdP E[X]=\\int XdP Wiki of Lebesgue integral, L^p L^p . Independence \u00b6 classic: P(A\\cap B)=P(A)P(B) P(A\\cap B)=P(A)P(B) . \\sigma \\sigma -algebra. R.V.s: \\sigma(X) \\sigma(X) indep. \\sigma(Y) \\sigma(Y) P-mutually independent \u00b6 A collection of events A_\\alpha\\subseteq\\mathcal{F} A_\\alpha\\subseteq\\mathcal{F} is P-m.indep. if for any L < \\infty L < \\infty distinct indices P(\\bigcap^L A_i) = \\prod^L P(A_i) P(\\bigcap^L A_i) = \\prod^L P(A_i) R.V.s: generated Borel. Theorem \u00b6 Finite P-m.indep. \\pi \\pi -system \\Rightarrow \\Rightarrow \\sigma (\\pi_n) \\sigma (\\pi_n) are P-m.indep. Corollary \u00b6 Above hold even for uncountably infinite . Since P-m.indep. condition only check finite L L . Theorem \u00b6 \\mathcal{F}_n^X \\mathcal{F}_n^X , \\sigma(X_{n+1}) \\sigma(X_{n+1}) P-m.indep. \\forall n \\forall n \\Rightarrow \\Rightarrow X_1,X_2,\\cdots X_1,X_2,\\cdots P-m.indep. \\Rightarrow \\Rightarrow \\mathcal{F}_n^X \\mathcal{F}_n^X , \\mathcal{T}_n^X \\mathcal{T}_n^X P-m.indep. Lemma \u00b6 if \\sigma \\sigma -algebras \\mathcal{G}_n\\uparrow \\mathcal{G} \\mathcal{G}_n\\uparrow \\mathcal{G} , each indep. with a \\sigma \\sigma -algebra \\mathcal{H}\\subseteq \\sigma(\\mathcal{G}) \\mathcal{H}\\subseteq \\sigma(\\mathcal{G}) , then \\mathcal{H} \\mathcal{H} is P-trivial. Kolmogorov's 0-1 law \u00b6 P-m.indep. S.P. \\{X_k\\} \\{X_k\\} \\Rightarrow \\Rightarrow \\mathcal{T}^X \\mathcal{T}^X is P-trivial. Proof \u00b6 A\\in T^X\\subseteq T_n^X A\\in T^X\\subseteq T_n^X imply T^X T^X , F_n^X F_n^X indep. Then by above lemma proved. \\square \\square Product \u00b6 Kolmogorov's extension theorem unique consistent probability measure. Fubini theorem ensure integral by parts","title":"Measurable function"},{"location":"measure/mf/#definition","text":"Mapping between two measurable spaces (\\Omega, \\mathcal{F}), (\\mathbb{S},\\mathcal{S}) (\\Omega, \\mathcal{F}), (\\mathbb{S},\\mathcal{S}) , also called measurable mapping, Borel function f f , random variable(R.V.) X X , if \\forall B\\in \\mathcal{S} \\forall B\\in \\mathcal{S} X^{-1}(B):= \\{A:X(A)\\in B\\} \\in\\mathcal{F} X^{-1}(B):= \\{A:X(A)\\in B\\} \\in\\mathcal{F} i.e. contain preimage.","title":"Definition"},{"location":"measure/mf/#convergence","text":"","title":"Convergence"},{"location":"measure/mf/#theorem","text":"\\rightarrow\\overline{\\mathbb{R}}, f_n\\in mF \\Rightarrow \\sup_n f_n,\\inf_n f_n, \\limsup_{n\\rightarrow\\infty}f_n,\\liminf f_n \\in mF \\rightarrow\\overline{\\mathbb{R}}, f_n\\in mF \\Rightarrow \\sup_n f_n,\\inf_n f_n, \\limsup_{n\\rightarrow\\infty}f_n,\\liminf f_n \\in mF","title":"Theorem"},{"location":"measure/mf/#theorem_1","text":"For any sequence f_n f_n \\Omega_0:=\\{ \\omega:\\liminf f = \\limsup f \\} \\\\\\\\ \\Omega_1:=\\{ \\omega:\\liminf f = \\limsup f \\in \\mathbb{R}\\} \\Omega_0:=\\{ \\omega:\\liminf f = \\limsup f \\} \\\\\\\\ \\Omega_1:=\\{ \\omega:\\liminf f = \\limsup f \\in \\mathbb{R}\\} are measurable, i.e. \\Omega_0,\\Omega_1 \\in F \\Omega_0,\\Omega_1 \\in F . set converge to \\infty \\infty or finite limit.","title":"Theorem"},{"location":"measure/mf/#type-of-convergence","text":"pointwise convergence: f_n(\\omega)\\rightarrow f(\\omega) f_n(\\omega)\\rightarrow f(\\omega) . a.s. convergence: f_n \\xrightarrow{a.s.}f f_n \\xrightarrow{a.s.}f , P(\\Omega_0) P(\\Omega_0) w.p.1. P(X_n\\rightarrow X)=1 P(X_n\\rightarrow X)=1 a.s. convergence to finite limit: P(\\Omega_1) P(\\Omega_1) w.p.1. convergence in probability: f_n \\xrightarrow{p}f f_n \\xrightarrow{p}f \\forall \\varepsilon>0 \\forall \\varepsilon>0 , P(x:|f_n(x)-f(x)|>\\varepsilon)\\rightarrow 0 P(x:|f_n(x)-f(x)|>\\varepsilon)\\rightarrow 0 . convergence in L^p L^p : f_n\\xrightarrow{L^p}f f_n\\xrightarrow{L^p}f f_n,f\\in L^p f_n,f\\in L^p , \\|f_n-f\\|_p\\rightarrow 0 \\|f_n-f\\|_p\\rightarrow 0 . (a.e.) pointwise is strong; a.s. means eventually, P(\\lim) P(\\lim) ; in probability, \\lim(P) \\lim(P) .","title":"Type of convergence"},{"location":"measure/mf/#relationship","text":"\\begin{align} \\xrightarrow{a.s.} &\\Rightarrow \\xrightarrow{p} \\\\\\\\ \\xrightarrow{L^p},p\\geq r &\\Rightarrow \\xrightarrow{L^r} \\\\\\\\ \\xrightarrow{L^p} &\\Rightarrow \\xrightarrow{p} \\end{align} \\begin{align} \\xrightarrow{a.s.} &\\Rightarrow \\xrightarrow{p} \\\\\\\\ \\xrightarrow{L^p},p\\geq r &\\Rightarrow \\xrightarrow{L^r} \\\\\\\\ \\xrightarrow{L^p} &\\Rightarrow \\xrightarrow{p} \\end{align} More properties on wiki .","title":"Relationship"},{"location":"measure/mf/#monotone-convergence-theorem","text":"f_n\\geq 0 f_n\\geq 0 pointwise converge, then \\mu(f_n)\\uparrow \\mu(f)\\leq \\infty \\mu(f_n)\\uparrow \\mu(f)\\leq \\infty .","title":"Monotone convergence theorem"},{"location":"measure/mf/#general","text":"f_n\\geq 0 f_n\\geq 0 , f_n\\uparrow f f_n\\uparrow f a.e., then Ef_n\\uparrow Ef Ef_n\\uparrow Ef .","title":"general"},{"location":"measure/mf/#fatous-lemma","text":"bridge \\limsup,\\liminf \\limsup,\\liminf on a.s. measure sense.","title":"Fatou's lemma"},{"location":"measure/mf/#dominated-convergence-theorem","text":"","title":"Dominated convergence theorem"},{"location":"measure/mf/#scheffes-lemma","text":"","title":"Scheffe's lemma"},{"location":"measure/mf/#ui","text":"","title":"U.I."},{"location":"measure/mf/#vitalis-convergence-theorem","text":"","title":"Vitali's convergence theorem"},{"location":"measure/mf/#standard-machine","text":"Steps to prove some property hold h\\in L^1 h\\in L^1 . prove indicator. by linearity, extent to SF_+ SF_+ by MON thm, extent to mF_+ mF_+ h=h_+-h_- h=h_+-h_- , extent to L^1 L^1","title":"Standard machine"},{"location":"measure/mf/#definition_1","text":"","title":"Definition"},{"location":"measure/mf/#distribution","text":"F:\\mathbb{R}\\rightarrow [0,1] F:\\mathbb{R}\\rightarrow [0,1] is distribution of some R.V. iff \\nearrow \\nearrow . imply a.s. differentiable. \\lim_{x\\rightarrow\\infty} F(x)=1 \\lim_{x\\rightarrow\\infty} F(x)=1 and \\lim_{x\\rightarrow -\\infty} F(x)= 0 \\lim_{x\\rightarrow -\\infty} F(x)= 0 right-continous: \\lim_{x\\downarrow a}F(x)=F(a) \\lim_{x\\downarrow a}F(x)=F(a)","title":"distribution"},{"location":"measure/mf/#pdf","text":"F_X(x)=\\int_{-\\infty}^xf_X(t)dt, \\forall x\\in \\mathbb{R} F_X(x)=\\int_{-\\infty}^xf_X(t)dt, \\forall x\\in \\mathbb{R}","title":"pdf"},{"location":"measure/mf/#p-trivial","text":"either P(A)=0 P(A)=0 or P(A^c)=0 P(A^c)=0 .","title":"P-trivial"},{"location":"measure/mf/#expectation","text":"E[X]=\\int XdP E[X]=\\int XdP Wiki of Lebesgue integral, L^p L^p .","title":"expectation"},{"location":"measure/mf/#independence","text":"classic: P(A\\cap B)=P(A)P(B) P(A\\cap B)=P(A)P(B) . \\sigma \\sigma -algebra. R.V.s: \\sigma(X) \\sigma(X) indep. \\sigma(Y) \\sigma(Y)","title":"Independence"},{"location":"measure/mf/#p-mutually-independent","text":"A collection of events A_\\alpha\\subseteq\\mathcal{F} A_\\alpha\\subseteq\\mathcal{F} is P-m.indep. if for any L < \\infty L < \\infty distinct indices P(\\bigcap^L A_i) = \\prod^L P(A_i) P(\\bigcap^L A_i) = \\prod^L P(A_i) R.V.s: generated Borel.","title":"P-mutually independent"},{"location":"measure/mf/#theorem_2","text":"Finite P-m.indep. \\pi \\pi -system \\Rightarrow \\Rightarrow \\sigma (\\pi_n) \\sigma (\\pi_n) are P-m.indep.","title":"Theorem"},{"location":"measure/mf/#corollary","text":"Above hold even for uncountably infinite . Since P-m.indep. condition only check finite L L .","title":"Corollary"},{"location":"measure/mf/#theorem_3","text":"\\mathcal{F}_n^X \\mathcal{F}_n^X , \\sigma(X_{n+1}) \\sigma(X_{n+1}) P-m.indep. \\forall n \\forall n \\Rightarrow \\Rightarrow X_1,X_2,\\cdots X_1,X_2,\\cdots P-m.indep. \\Rightarrow \\Rightarrow \\mathcal{F}_n^X \\mathcal{F}_n^X , \\mathcal{T}_n^X \\mathcal{T}_n^X P-m.indep.","title":"Theorem"},{"location":"measure/mf/#lemma","text":"if \\sigma \\sigma -algebras \\mathcal{G}_n\\uparrow \\mathcal{G} \\mathcal{G}_n\\uparrow \\mathcal{G} , each indep. with a \\sigma \\sigma -algebra \\mathcal{H}\\subseteq \\sigma(\\mathcal{G}) \\mathcal{H}\\subseteq \\sigma(\\mathcal{G}) , then \\mathcal{H} \\mathcal{H} is P-trivial.","title":"Lemma"},{"location":"measure/mf/#kolmogorovs-0-1-law","text":"P-m.indep. S.P. \\{X_k\\} \\{X_k\\} \\Rightarrow \\Rightarrow \\mathcal{T}^X \\mathcal{T}^X is P-trivial.","title":"Kolmogorov's 0-1 law"},{"location":"measure/mf/#proof","text":"A\\in T^X\\subseteq T_n^X A\\in T^X\\subseteq T_n^X imply T^X T^X , F_n^X F_n^X indep. Then by above lemma proved. \\square \\square","title":"Proof"},{"location":"measure/mf/#product","text":"Kolmogorov's extension theorem unique consistent probability measure. Fubini theorem ensure integral by parts","title":"Product"},{"location":"measure/sigma/","text":"Definition \u00b6 \\sigma \\sigma -algebra \u00b6 \\mathcal{F} \\mathcal{F} is \\sigma \\sigma -algebra if closed under completement : A\\in \\mathcal{F} A\\in \\mathcal{F} imply \\Omega/A = A^c \\in \\mathcal{F} \\Omega/A = A^c \\in \\mathcal{F} . \\Omega \\in \\mathcal{F} \\Omega \\in \\mathcal{F} . assuming (1), equiv to \\varnothing\\in\\mathcal{F} \\varnothing\\in\\mathcal{F} . closed unded countable union: A_i\\in\\mathcal{F} A_i\\in\\mathcal{F} imply \\bigcup_i A_i\\in \\mathcal{F} \\bigcup_i A_i\\in \\mathcal{F} . assuming (1),(2), equiv to closed under countable intersection \\bigcap_i A_i\\in\\mathcal{F} \\bigcap_i A_i\\in\\mathcal{F} , by De Morgan's law. measure \u00b6 \\mu:\\mathcal{F}\\rightarrow [0,\\infty] \\mu:\\mathcal{F}\\rightarrow [0,\\infty] is measure if \\mu(A)\\geq \\mu(\\varnothing)=0, \\forall A\\in \\mathcal{F} \\mu(A)\\geq \\mu(\\varnothing)=0, \\forall A\\in \\mathcal{F} coutably additive: \\mu(\\bigcup_i A_i) = \\sum_i \\mu(A_i) \\mu(\\bigcup_i A_i) = \\sum_i \\mu(A_i) for mutually exclusive events. \\mu(\\Omega)=1 \\mu(\\Omega)=1 denoted probability measure, label with P P . properties \u00b6 monotonicity: A_1 \\subseteq A_2\\Rightarrow \\mu(A_1)\\leq \\mu(A_2) A_1 \\subseteq A_2\\Rightarrow \\mu(A_1)\\leq \\mu(A_2) . sub-additivity: \\mu(\\bigcup_i A_i)\\leq \\sum_i\\mu(A_i) \\mu(\\bigcup_i A_i)\\leq \\sum_i\\mu(A_i) . continuity from below: A_i\\uparrow A \\Rightarrow \\mu(A_i)\\uparrow \\mu(A) A_i\\uparrow A \\Rightarrow \\mu(A_i)\\uparrow \\mu(A) . continuity from above: if at aleast one A_i A_i measure finite, A_i\\downarrow A \\Rightarrow \\mu(A_i)\\downarrow \\mu(A) A_i\\downarrow A \\Rightarrow \\mu(A_i)\\downarrow \\mu(A) . generated \\sigma \\sigma \u00b6 used for implicitly claim \\sigma \\sigma -algebra. smallest \\sigma \\sigma -algebra \\mathcal{F} \\mathcal{F} of A_\\alpha\\subseteq \\Omega A_\\alpha\\subseteq \\Omega s.t. A_\\alpha\\in\\mathcal{F}, \\forall \\alpha A_\\alpha\\in\\mathcal{F}, \\forall \\alpha , that is $$ \\sigma({A_\\alpha})=\\sigma(A_\\alpha, \\alpha\\in\\Gamma)=\\bigcap {\\mathcal{G}:\\mathcal{G}\\subseteq 2^\\Omega \\text{ is } \\sigma, A_\\alpha\\in\\mathcal{G}, \\forall \\alpha\\in\\Gamma} $$ denote generated on topology \\mathbb{S} \\mathbb{S} as \\mathcal{B}_\\mathbb{S}=\\sigma(\\{ O\\subseteq \\mathbb{S} \\text{ open}\\}) \\mathcal{B}_\\mathbb{S}=\\sigma(\\{ O\\subseteq \\mathbb{S} \\text{ open}\\}) , implicitly denote \\mathcal{B}=\\mathcal{B}_\\mathbb{R} \\mathcal{B}=\\mathcal{B}_\\mathbb{R} . Caratheodory's extension theorem \u00b6 If \\mu_0: \\mathcal{A}\\rightarrow [0,\\infty] \\mu_0: \\mathcal{A}\\rightarrow [0,\\infty] is a countably additive set function on an algebra \\mathcal{A} \\mathcal{A} , then there exists a measure \\mu \\mu on (\\Omega, \\sigma(\\mathcal{A})) (\\Omega, \\sigma(\\mathcal{A})) s.t. \\mu=\\mu_0 \\mu=\\mu_0 on \\mathcal{A} \\mathcal{A} . Furthermore, if \\mu_0(\\Omega)<\\infty \\mu_0(\\Omega)<\\infty then such a measure \\mu \\mu is unique. countably additive, algebra \\Rightarrow \\Rightarrow \\sigma \\sigma -algebra. Completeness \u00b6 Definition \u00b6 A measure space is called complete, if N\\subseteq A, A\\in \\mathcal{F}, \\mu(A)=0 N\\subseteq A, A\\in \\mathcal{F}, \\mu(A)=0 , then N\\in\\mathcal{F} N\\in\\mathcal{F} . contain null-sets. Theorem \u00b6 measure space has its completion. Dynkin \u00b6 Definition \u00b6 \\pi \\pi -system: closed under finite intersections. \\lambda \\lambda -system: contain \\Omega \\Omega and B\\setminus A,\\forall A\\subseteq B,A,B\\in \\mathcal{L} B\\setminus A,\\forall A\\subseteq B,A,B\\in \\mathcal{L} . which is also closed under monotone increasing limits(i.e. if A_i\\in\\mathcal{L} A_i\\in\\mathcal{L} and A_i\\uparrow A A_i\\uparrow A , then A\\in\\mathcal{L} A\\in\\mathcal{L} ) contain \\Omega \\Omega , closed under completement, closed under countable disjoint union. Theorem \u00b6 \\sigma \\sigma -algebra \\Leftrightarrow \\Leftrightarrow \\pi \\pi -system and \\lambda \\lambda -system. \\pi \\pi - \\lambda \\lambda theorem \u00b6 If P_\\pi \\subseteq L_\\lambda P_\\pi \\subseteq L_\\lambda , then \\sigma(P_\\pi)\\subseteq L_\\lambda \\sigma(P_\\pi)\\subseteq L_\\lambda . Monotone class \u00b6 closed under monotone limits. Halmos monotone class theorem \u00b6 algebra \\mathcal{A}\\subseteq \\mathcal{M}\\Rightarrow \\sigma(\\mathcal{A})\\subseteq \\mathcal{M} \\mathcal{A}\\subseteq \\mathcal{M}\\Rightarrow \\sigma(\\mathcal{A})\\subseteq \\mathcal{M} . Banach-Tarski paradox \u00b6 respect to axiom of choice, a ball is equidecomposable to two balls. Collorary \u00b6 \\exists A\\subseteq \\mathbb{R} \\exists A\\subseteq \\mathbb{R} that A\\notin\\mathcal{B} A\\notin\\mathcal{B} .","title":"Sigma"},{"location":"measure/sigma/#definition","text":"","title":"Definition"},{"location":"measure/sigma/#sigmasigma-algebra","text":"\\mathcal{F} \\mathcal{F} is \\sigma \\sigma -algebra if closed under completement : A\\in \\mathcal{F} A\\in \\mathcal{F} imply \\Omega/A = A^c \\in \\mathcal{F} \\Omega/A = A^c \\in \\mathcal{F} . \\Omega \\in \\mathcal{F} \\Omega \\in \\mathcal{F} . assuming (1), equiv to \\varnothing\\in\\mathcal{F} \\varnothing\\in\\mathcal{F} . closed unded countable union: A_i\\in\\mathcal{F} A_i\\in\\mathcal{F} imply \\bigcup_i A_i\\in \\mathcal{F} \\bigcup_i A_i\\in \\mathcal{F} . assuming (1),(2), equiv to closed under countable intersection \\bigcap_i A_i\\in\\mathcal{F} \\bigcap_i A_i\\in\\mathcal{F} , by De Morgan's law.","title":"\\sigma\\sigma-algebra"},{"location":"measure/sigma/#measure","text":"\\mu:\\mathcal{F}\\rightarrow [0,\\infty] \\mu:\\mathcal{F}\\rightarrow [0,\\infty] is measure if \\mu(A)\\geq \\mu(\\varnothing)=0, \\forall A\\in \\mathcal{F} \\mu(A)\\geq \\mu(\\varnothing)=0, \\forall A\\in \\mathcal{F} coutably additive: \\mu(\\bigcup_i A_i) = \\sum_i \\mu(A_i) \\mu(\\bigcup_i A_i) = \\sum_i \\mu(A_i) for mutually exclusive events. \\mu(\\Omega)=1 \\mu(\\Omega)=1 denoted probability measure, label with P P .","title":"measure"},{"location":"measure/sigma/#properties","text":"monotonicity: A_1 \\subseteq A_2\\Rightarrow \\mu(A_1)\\leq \\mu(A_2) A_1 \\subseteq A_2\\Rightarrow \\mu(A_1)\\leq \\mu(A_2) . sub-additivity: \\mu(\\bigcup_i A_i)\\leq \\sum_i\\mu(A_i) \\mu(\\bigcup_i A_i)\\leq \\sum_i\\mu(A_i) . continuity from below: A_i\\uparrow A \\Rightarrow \\mu(A_i)\\uparrow \\mu(A) A_i\\uparrow A \\Rightarrow \\mu(A_i)\\uparrow \\mu(A) . continuity from above: if at aleast one A_i A_i measure finite, A_i\\downarrow A \\Rightarrow \\mu(A_i)\\downarrow \\mu(A) A_i\\downarrow A \\Rightarrow \\mu(A_i)\\downarrow \\mu(A) .","title":"properties"},{"location":"measure/sigma/#generated-sigmasigma","text":"used for implicitly claim \\sigma \\sigma -algebra. smallest \\sigma \\sigma -algebra \\mathcal{F} \\mathcal{F} of A_\\alpha\\subseteq \\Omega A_\\alpha\\subseteq \\Omega s.t. A_\\alpha\\in\\mathcal{F}, \\forall \\alpha A_\\alpha\\in\\mathcal{F}, \\forall \\alpha , that is $$ \\sigma({A_\\alpha})=\\sigma(A_\\alpha, \\alpha\\in\\Gamma)=\\bigcap {\\mathcal{G}:\\mathcal{G}\\subseteq 2^\\Omega \\text{ is } \\sigma, A_\\alpha\\in\\mathcal{G}, \\forall \\alpha\\in\\Gamma} $$ denote generated on topology \\mathbb{S} \\mathbb{S} as \\mathcal{B}_\\mathbb{S}=\\sigma(\\{ O\\subseteq \\mathbb{S} \\text{ open}\\}) \\mathcal{B}_\\mathbb{S}=\\sigma(\\{ O\\subseteq \\mathbb{S} \\text{ open}\\}) , implicitly denote \\mathcal{B}=\\mathcal{B}_\\mathbb{R} \\mathcal{B}=\\mathcal{B}_\\mathbb{R} .","title":"generated \\sigma\\sigma"},{"location":"measure/sigma/#caratheodorys-extension-theorem","text":"If \\mu_0: \\mathcal{A}\\rightarrow [0,\\infty] \\mu_0: \\mathcal{A}\\rightarrow [0,\\infty] is a countably additive set function on an algebra \\mathcal{A} \\mathcal{A} , then there exists a measure \\mu \\mu on (\\Omega, \\sigma(\\mathcal{A})) (\\Omega, \\sigma(\\mathcal{A})) s.t. \\mu=\\mu_0 \\mu=\\mu_0 on \\mathcal{A} \\mathcal{A} . Furthermore, if \\mu_0(\\Omega)<\\infty \\mu_0(\\Omega)<\\infty then such a measure \\mu \\mu is unique. countably additive, algebra \\Rightarrow \\Rightarrow \\sigma \\sigma -algebra.","title":"Caratheodory's extension theorem"},{"location":"measure/sigma/#completeness","text":"","title":"Completeness"},{"location":"measure/sigma/#definition_1","text":"A measure space is called complete, if N\\subseteq A, A\\in \\mathcal{F}, \\mu(A)=0 N\\subseteq A, A\\in \\mathcal{F}, \\mu(A)=0 , then N\\in\\mathcal{F} N\\in\\mathcal{F} . contain null-sets.","title":"Definition"},{"location":"measure/sigma/#theorem","text":"measure space has its completion.","title":"Theorem"},{"location":"measure/sigma/#dynkin","text":"","title":"Dynkin"},{"location":"measure/sigma/#definition_2","text":"\\pi \\pi -system: closed under finite intersections. \\lambda \\lambda -system: contain \\Omega \\Omega and B\\setminus A,\\forall A\\subseteq B,A,B\\in \\mathcal{L} B\\setminus A,\\forall A\\subseteq B,A,B\\in \\mathcal{L} . which is also closed under monotone increasing limits(i.e. if A_i\\in\\mathcal{L} A_i\\in\\mathcal{L} and A_i\\uparrow A A_i\\uparrow A , then A\\in\\mathcal{L} A\\in\\mathcal{L} ) contain \\Omega \\Omega , closed under completement, closed under countable disjoint union.","title":"Definition"},{"location":"measure/sigma/#theorem_1","text":"\\sigma \\sigma -algebra \\Leftrightarrow \\Leftrightarrow \\pi \\pi -system and \\lambda \\lambda -system.","title":"Theorem"},{"location":"measure/sigma/#pipi-lambdalambda-theorem","text":"If P_\\pi \\subseteq L_\\lambda P_\\pi \\subseteq L_\\lambda , then \\sigma(P_\\pi)\\subseteq L_\\lambda \\sigma(P_\\pi)\\subseteq L_\\lambda .","title":"\\pi\\pi-\\lambda\\lambda theorem"},{"location":"measure/sigma/#monotone-class","text":"closed under monotone limits.","title":"Monotone class"},{"location":"measure/sigma/#halmos-monotone-class-theorem","text":"algebra \\mathcal{A}\\subseteq \\mathcal{M}\\Rightarrow \\sigma(\\mathcal{A})\\subseteq \\mathcal{M} \\mathcal{A}\\subseteq \\mathcal{M}\\Rightarrow \\sigma(\\mathcal{A})\\subseteq \\mathcal{M} .","title":"Halmos monotone class theorem"},{"location":"measure/sigma/#banach-tarski-paradox","text":"respect to axiom of choice, a ball is equidecomposable to two balls.","title":"Banach-Tarski paradox"},{"location":"measure/sigma/#collorary","text":"\\exists A\\subseteq \\mathbb{R} \\exists A\\subseteq \\mathbb{R} that A\\notin\\mathcal{B} A\\notin\\mathcal{B} .","title":"Collorary"},{"location":"measure/martingale/branch/","text":"Description \u00b6 A reproduction model, random tree, Galton-Watson process. Z_{n+1} = \\sum_{i=1}^{Z_n} X_{n,i} Z_{n+1} = \\sum_{i=1}^{Z_n} X_{n,i} with Z_0=1 Z_0=1 , X_{n,i} X_{n,i} are i.i.d. \\mathbb{N} \\mathbb{N} R.V.s to n,i n,i , i.e. to generation and each. extinction \u00b6 \\{ \\omega: Z_n(\\omega)=0, ev. \\} \\{ \\omega: Z_n(\\omega)=0, ev. \\} mgf \u00b6 L(s) = E[s^X] L(s) = E[s^X] MG \u00b6 \\mu^{-n}Z_n \\mu^{-n}Z_n is MG, \\rho^{Z_n} \\rho^{Z_n} is MG for \\rho=L(\\rho) \\rho=L(\\rho) . Proposition. Extinction \u00b6 For nontrivial, i.e. P(X=0)\\in(0,1) P(X=0)\\in(0,1) . If \\mu \\leq 1 \\mu \\leq 1 , then p_{ex}=1 p_{ex}=1 . If \\mu > 1 \\mu > 1 , then p_{ex} = \\rho p_{ex} = \\rho , \\mu^{-n}Z_n\\xrightarrow{a.s.} \\mu^{-n}Z_n\\xrightarrow{a.s.} , and that Z_n\\xrightarrow{a.s.}\\{0,\\infty\\} Z_n\\xrightarrow{a.s.}\\{0,\\infty\\} More about product MG \u00b6 Kakutani\u2019s Theorem \u00b6","title":"Branching process"},{"location":"measure/martingale/branch/#description","text":"A reproduction model, random tree, Galton-Watson process. Z_{n+1} = \\sum_{i=1}^{Z_n} X_{n,i} Z_{n+1} = \\sum_{i=1}^{Z_n} X_{n,i} with Z_0=1 Z_0=1 , X_{n,i} X_{n,i} are i.i.d. \\mathbb{N} \\mathbb{N} R.V.s to n,i n,i , i.e. to generation and each.","title":"Description"},{"location":"measure/martingale/branch/#extinction","text":"\\{ \\omega: Z_n(\\omega)=0, ev. \\} \\{ \\omega: Z_n(\\omega)=0, ev. \\}","title":"extinction"},{"location":"measure/martingale/branch/#mgf","text":"L(s) = E[s^X] L(s) = E[s^X]","title":"mgf"},{"location":"measure/martingale/branch/#mg","text":"\\mu^{-n}Z_n \\mu^{-n}Z_n is MG, \\rho^{Z_n} \\rho^{Z_n} is MG for \\rho=L(\\rho) \\rho=L(\\rho) .","title":"MG"},{"location":"measure/martingale/branch/#proposition-extinction","text":"For nontrivial, i.e. P(X=0)\\in(0,1) P(X=0)\\in(0,1) . If \\mu \\leq 1 \\mu \\leq 1 , then p_{ex}=1 p_{ex}=1 . If \\mu > 1 \\mu > 1 , then p_{ex} = \\rho p_{ex} = \\rho , \\mu^{-n}Z_n\\xrightarrow{a.s.} \\mu^{-n}Z_n\\xrightarrow{a.s.} , and that Z_n\\xrightarrow{a.s.}\\{0,\\infty\\} Z_n\\xrightarrow{a.s.}\\{0,\\infty\\}","title":"Proposition. Extinction"},{"location":"measure/martingale/branch/#more-about-product-mg","text":"","title":"More about product MG"},{"location":"measure/martingale/branch/#kakutanis-theorem","text":"","title":"Kakutani\u2019s Theorem"},{"location":"measure/martingale/dct/","text":"Lemma \u00b6 Each a<b a<b , U_\\infty[a,b]<\\infty U_\\infty[a,b]<\\infty a.s., then X_n\\xrightarrow{a.s.}X X_n\\xrightarrow{a.s.}X . b-a\\rightarrow0 b-a\\rightarrow0 , U_\\infty U_\\infty finite, roughly imply \\liminf=\\limsup \\liminf=\\limsup w.p.1. Theorem. DCT \u00b6 sup-MG, \\sup_n E(X_n)_-<\\infty \\sup_n E(X_n)_-<\\infty , then X_n\\xrightarrow{a.s.}X X_n\\xrightarrow{a.s.}X . intuitively, the losing part is bounded, thus down-crossing is finite. for sub-MG, some equivalent conditions: \\sup_n E(X_n)_+ < \\infty \\sup_n E(X_n)_+ < \\infty . \\sup_n E|X_n| < \\infty \\sup_n E|X_n| < \\infty . \\lim_n E|X_n|<\\infty \\lim_n E|X_n|<\\infty . \\lim_n E(X_n)_+ < \\infty \\lim_n E(X_n)_+ < \\infty . \\liminf_n E|X_n| < \\infty \\liminf_n E|X_n| < \\infty . Corollary. Inequality \u00b6 U.I. sub-MG, a>0 a>0 , P(X_k\\geq a,\\exists k<\\infty) \\leq a^{-1} E(X_\\infty)_+ P(X_k\\geq a,\\exists k<\\infty) \\leq a^{-1} E(X_\\infty)_+ Proposition. \u00b6 MG, \\sup_n|X_n-X_{n-1}|\\leq c \\sup_n|X_n-X_{n-1}|\\leq c , a.s. then P(A\\cup B)=1 P(A\\cup B)=1 with A = \\{\\omega: \\lim X_n(\\omega)<\\infty \\} \\\\\\\\ B = \\{\\omega: \\liminf X_n(\\omega)=-\\infty, \\limsup X_n(\\omega)=\\infty\\} A = \\{\\omega: \\lim X_n(\\omega)<\\infty \\} \\\\\\\\ B = \\{\\omega: \\liminf X_n(\\omega)=-\\infty, \\limsup X_n(\\omega)=\\infty\\} either can walk everywhere or convergence. more applications 5.3.x \u00b6 lemma \u00b6 DCT condition, then E|X_\\tau|<\\infty,\\forall\\tau E|X_\\tau|<\\infty,\\forall\\tau . Proposition \u00b6 sup-MG \\geq 0, \\theta\\leq \\tau \\geq 0, \\theta\\leq \\tau , then EX_\\theta \\leq EX_\\tau<\\infty EX_\\theta \\leq EX_\\tau<\\infty . L\u00e9vy's 0-1 law \u00b6 \\mathcal{F}_n\\uparrow \\mathcal{F}, A\\in \\mathcal{F} \\mathcal{F}_n\\uparrow \\mathcal{F}, A\\in \\mathcal{F} , then E[I_A|\\mathcal{F}_n]\\xrightarrow{a.s.}I_A E[I_A|\\mathcal{F}_n]\\xrightarrow{a.s.}I_A . gradually with more information, we will be certain about the outcome. Thus P(A)=I_A P(A)=I_A a.s. deducing Kolmogorov's 0-1 law. Doob's L^p L^p martingale convergence \u00b6 MG, \\sup_n E|X_n|^p < \\infty, p>1 \\sup_n E|X_n|^p < \\infty, p>1 , then X_n\\rightarrow X X_n\\rightarrow X a.s. and L_p L_p (So \\|X_n\\|_p\\rightarrow\\|X\\|_p \\|X_n\\|_p\\rightarrow\\|X\\|_p ).","title":"Doob's convergence theorem"},{"location":"measure/martingale/dct/#lemma","text":"Each a<b a<b , U_\\infty[a,b]<\\infty U_\\infty[a,b]<\\infty a.s., then X_n\\xrightarrow{a.s.}X X_n\\xrightarrow{a.s.}X . b-a\\rightarrow0 b-a\\rightarrow0 , U_\\infty U_\\infty finite, roughly imply \\liminf=\\limsup \\liminf=\\limsup w.p.1.","title":"Lemma"},{"location":"measure/martingale/dct/#theorem-dct","text":"sup-MG, \\sup_n E(X_n)_-<\\infty \\sup_n E(X_n)_-<\\infty , then X_n\\xrightarrow{a.s.}X X_n\\xrightarrow{a.s.}X . intuitively, the losing part is bounded, thus down-crossing is finite. for sub-MG, some equivalent conditions: \\sup_n E(X_n)_+ < \\infty \\sup_n E(X_n)_+ < \\infty . \\sup_n E|X_n| < \\infty \\sup_n E|X_n| < \\infty . \\lim_n E|X_n|<\\infty \\lim_n E|X_n|<\\infty . \\lim_n E(X_n)_+ < \\infty \\lim_n E(X_n)_+ < \\infty . \\liminf_n E|X_n| < \\infty \\liminf_n E|X_n| < \\infty .","title":"Theorem. DCT"},{"location":"measure/martingale/dct/#corollary-inequality","text":"U.I. sub-MG, a>0 a>0 , P(X_k\\geq a,\\exists k<\\infty) \\leq a^{-1} E(X_\\infty)_+ P(X_k\\geq a,\\exists k<\\infty) \\leq a^{-1} E(X_\\infty)_+","title":"Corollary. Inequality"},{"location":"measure/martingale/dct/#proposition","text":"MG, \\sup_n|X_n-X_{n-1}|\\leq c \\sup_n|X_n-X_{n-1}|\\leq c , a.s. then P(A\\cup B)=1 P(A\\cup B)=1 with A = \\{\\omega: \\lim X_n(\\omega)<\\infty \\} \\\\\\\\ B = \\{\\omega: \\liminf X_n(\\omega)=-\\infty, \\limsup X_n(\\omega)=\\infty\\} A = \\{\\omega: \\lim X_n(\\omega)<\\infty \\} \\\\\\\\ B = \\{\\omega: \\liminf X_n(\\omega)=-\\infty, \\limsup X_n(\\omega)=\\infty\\} either can walk everywhere or convergence.","title":"Proposition."},{"location":"measure/martingale/dct/#more-applications-53x","text":"","title":"more applications 5.3.x"},{"location":"measure/martingale/dct/#lemma_1","text":"DCT condition, then E|X_\\tau|<\\infty,\\forall\\tau E|X_\\tau|<\\infty,\\forall\\tau .","title":"lemma"},{"location":"measure/martingale/dct/#proposition_1","text":"sup-MG \\geq 0, \\theta\\leq \\tau \\geq 0, \\theta\\leq \\tau , then EX_\\theta \\leq EX_\\tau<\\infty EX_\\theta \\leq EX_\\tau<\\infty .","title":"Proposition"},{"location":"measure/martingale/dct/#levys-0-1-law","text":"\\mathcal{F}_n\\uparrow \\mathcal{F}, A\\in \\mathcal{F} \\mathcal{F}_n\\uparrow \\mathcal{F}, A\\in \\mathcal{F} , then E[I_A|\\mathcal{F}_n]\\xrightarrow{a.s.}I_A E[I_A|\\mathcal{F}_n]\\xrightarrow{a.s.}I_A . gradually with more information, we will be certain about the outcome. Thus P(A)=I_A P(A)=I_A a.s. deducing Kolmogorov's 0-1 law.","title":"L\u00e9vy's 0-1 law"},{"location":"measure/martingale/dct/#doobs-lplp-martingale-convergence","text":"MG, \\sup_n E|X_n|^p < \\infty, p>1 \\sup_n E|X_n|^p < \\infty, p>1 , then X_n\\rightarrow X X_n\\rightarrow X a.s. and L_p L_p (So \\|X_n\\|_p\\rightarrow\\|X\\|_p \\|X_n\\|_p\\rightarrow\\|X\\|_p ).","title":"Doob's L^pL^p martingale convergence"},{"location":"measure/martingale/ddecomp/","text":"Proposition. Convex \u00b6 E|\\varphi(X_n)|<\\infty,\\forall n E|\\varphi(X_n)|<\\infty,\\forall n , then MG \\Rightarrow \\Rightarrow \\varphi(X_n) \\varphi(X_n) is sub-MG sub-MG. \\varphi\\nearrow \\varphi\\nearrow \\Rightarrow \\Rightarrow \\varphi(X_n) \\varphi(X_n) is sub-MG. Theorem. stopped at \u00b6 sub-MG, \\theta\\leq\\tau \\theta\\leq\\tau , then X_{n\\wedge\\tau} - X_{n\\wedge\\theta} X_{n\\wedge\\tau} - X_{n\\wedge\\theta} is sub-MG, in particular, X_{n\\wedge\\tau} X_{n\\wedge\\tau} is sub-MG. Collorary \u00b6 EX_{n\\wedge\\tau} \\geq EX_{n\\wedge\\theta} EX_{n\\wedge\\tau} \\geq EX_{n\\wedge\\theta} Doob's decomposition theorem \u00b6 For S.P. X_n X_n , \\exists \\exists MG Y_n Y_n ,predictable A_n A_n , that $$ X_n=Y_n+A_n $$ unique to Y_0 Y_0 . Collorary \u00b6 sub-MG X_n X_n iff A\\nearrow A\\nearrow .","title":"Doob's decomposition theorem"},{"location":"measure/martingale/ddecomp/#proposition-convex","text":"E|\\varphi(X_n)|<\\infty,\\forall n E|\\varphi(X_n)|<\\infty,\\forall n , then MG \\Rightarrow \\Rightarrow \\varphi(X_n) \\varphi(X_n) is sub-MG sub-MG. \\varphi\\nearrow \\varphi\\nearrow \\Rightarrow \\Rightarrow \\varphi(X_n) \\varphi(X_n) is sub-MG.","title":"Proposition. Convex"},{"location":"measure/martingale/ddecomp/#theorem-stopped-at","text":"sub-MG, \\theta\\leq\\tau \\theta\\leq\\tau , then X_{n\\wedge\\tau} - X_{n\\wedge\\theta} X_{n\\wedge\\tau} - X_{n\\wedge\\theta} is sub-MG, in particular, X_{n\\wedge\\tau} X_{n\\wedge\\tau} is sub-MG.","title":"Theorem. stopped at"},{"location":"measure/martingale/ddecomp/#collorary","text":"EX_{n\\wedge\\tau} \\geq EX_{n\\wedge\\theta} EX_{n\\wedge\\tau} \\geq EX_{n\\wedge\\theta}","title":"Collorary"},{"location":"measure/martingale/ddecomp/#doobs-decomposition-theorem","text":"For S.P. X_n X_n , \\exists \\exists MG Y_n Y_n ,predictable A_n A_n , that $$ X_n=Y_n+A_n $$ unique to Y_0 Y_0 .","title":"Doob's decomposition theorem"},{"location":"measure/martingale/ddecomp/#collorary_1","text":"sub-MG X_n X_n iff A\\nearrow A\\nearrow .","title":"Collorary"},{"location":"measure/martingale/def/","text":"This page is about discrete time martingale. filtration \u00b6 \\mathcal{F}_n\\uparrow \\mathcal{F}=\\sigma(\\bigcup_iF_i) \\mathcal{F}_n\\uparrow \\mathcal{F}=\\sigma(\\bigcup_iF_i) adapted \u00b6 A S.P. \\{X_n\\} \\{X_n\\} is adpated to a filtration, denoted as \\mathcal{F}_n \\mathcal{F}_n -adapted, if \\sigma(X_n)\\subseteq \\mathcal{F}_n, \\forall n \\sigma(X_n)\\subseteq \\mathcal{F}_n, \\forall n . iff \\sigma(X_0,X_1,\\cdots,X_n)\\subseteq\\mathcal{F}_n \\sigma(X_0,X_1,\\cdots,X_n)\\subseteq\\mathcal{F}_n canonical(minimal) filtration \u00b6 $$ \\mathcal{F}_n^X = \\sigma(X_0,X_1,\\cdots,X_n) $$ Implicitly w.r.t. martingale(MG) \u00b6 E|X_n|<\\infty E|X_n|<\\infty , $$ E[X_{n+1}|\\mathcal{F}_n]=X_n, \\forall n, a.s. $$ difference characterization \u00b6 let D_n=X_n-X_{n-1} D_n=X_n-X_{n-1} , i.e. X_n=\\sum^n D_i X_n=\\sum^n D_i , $$ E[D_{n+1}|\\mathcal{F}_n]=0, \\forall n, a.s. $$ Knowing past information, zero profit, i.e. fair game. product MG \u00b6 indep. Y_n\\geq 0 Y_n\\geq 0 . M_n=\\prod^nY_i M_n=\\prod^nY_i , E[M_{n+1}|\\mathcal{F}_n^Y]=M_nE[Y_{n+1}]=M_n \\Leftrightarrow E[Y_n]=1,\\forall n E[M_{n+1}|\\mathcal{F}_n^Y]=M_nE[Y_{n+1}]=M_n \\Leftrightarrow E[Y_n]=1,\\forall n or general condition E[Y_{n+1}|\\mathcal{F}_n^Y]=1 E[Y_{n+1}|\\mathcal{F}_n^Y]=1 a.s. sub-MG \u00b6 E[X_{n+1}|\\mathcal{F}_n]\\geq X_n, \\forall n, a.s. E[X_{n+1}|\\mathcal{F}_n]\\geq X_n, \\forall n, a.s. Implicitly used for sub-MG, sup-MG or MG. strong MG \u00b6 MG iff E[X_n|\\mathcal{F}_\\tau]=X_\\tau, \\forall\\tau\\leq n,\\forall n E[X_n|\\mathcal{F}_\\tau]=X_\\tau, \\forall\\tau\\leq n,\\forall n local MG \u00b6 stopping time \u00b6 A R.V. \\tau \\tau values \\mathbb{N}\\cup\\infty \\mathbb{N}\\cup\\infty for filtration \\{\\mathcal{F}_n\\} \\{\\mathcal{F}_n\\} , if \\{\\omega:\\tau(\\omega)\\leq n\\}\\in\\mathcal{F}_n,\\forall n \\{\\omega:\\tau(\\omega)\\leq n\\}\\in\\mathcal{F}_n,\\forall n stopped at \u00b6 X_{n\\wedge\\tau}(\\omega) = \\begin{cases}X_n(\\omega), n\\leq\\tau(\\omega) \\\\\\\\ X_{\\tau(\\omega)}(\\omega), n>\\tau(\\omega)\\end{cases} X_{n\\wedge\\tau}(\\omega) = \\begin{cases}X_n(\\omega), n\\leq\\tau(\\omega) \\\\\\\\ X_{\\tau(\\omega)}(\\omega), n>\\tau(\\omega)\\end{cases} stopped \\sigma \\sigma -algebra \u00b6 \\mathcal{F}_\\tau:=\\{A\\in\\mathcal{F}:A\\cap\\{\\omega:\\tau(\\omega)\\leq n\\}\\in\\mathcal{F}_n,\\forall n\\} \\mathcal{F}_\\tau:=\\{A\\in\\mathcal{F}:A\\cap\\{\\omega:\\tau(\\omega)\\leq n\\}\\in\\mathcal{F}_n,\\forall n\\} pridictable \u00b6 V_n\\in m\\mathcal{F}_{n-1},\\forall n V_n\\in m\\mathcal{F}_{n-1},\\forall n MG transform \u00b6 Y_n = \\sum^n V_i(X_i-X_{i-1}) Y_n = \\sum^n V_i(X_i-X_{i-1}) up-crossings \u00b6 number of up-crossings U_n[a,b] U_n[a,b] , largest l, (s_i,t_i)_l l, (s_i,t_i)_l s.t. X_s<a<b<X_t, s_1<t_1<s_2<\\cdots X_s<a<b<X_t, s_1<t_1<s_2<\\cdots","title":"Definitions"},{"location":"measure/martingale/def/#filtration","text":"\\mathcal{F}_n\\uparrow \\mathcal{F}=\\sigma(\\bigcup_iF_i) \\mathcal{F}_n\\uparrow \\mathcal{F}=\\sigma(\\bigcup_iF_i)","title":"filtration"},{"location":"measure/martingale/def/#adapted","text":"A S.P. \\{X_n\\} \\{X_n\\} is adpated to a filtration, denoted as \\mathcal{F}_n \\mathcal{F}_n -adapted, if \\sigma(X_n)\\subseteq \\mathcal{F}_n, \\forall n \\sigma(X_n)\\subseteq \\mathcal{F}_n, \\forall n . iff \\sigma(X_0,X_1,\\cdots,X_n)\\subseteq\\mathcal{F}_n \\sigma(X_0,X_1,\\cdots,X_n)\\subseteq\\mathcal{F}_n","title":"adapted"},{"location":"measure/martingale/def/#canonicalminimal-filtration","text":"$$ \\mathcal{F}_n^X = \\sigma(X_0,X_1,\\cdots,X_n) $$ Implicitly w.r.t.","title":"canonical(minimal) filtration"},{"location":"measure/martingale/def/#martingalemg","text":"E|X_n|<\\infty E|X_n|<\\infty , $$ E[X_{n+1}|\\mathcal{F}_n]=X_n, \\forall n, a.s. $$","title":"martingale(MG)"},{"location":"measure/martingale/def/#difference-characterization","text":"let D_n=X_n-X_{n-1} D_n=X_n-X_{n-1} , i.e. X_n=\\sum^n D_i X_n=\\sum^n D_i , $$ E[D_{n+1}|\\mathcal{F}_n]=0, \\forall n, a.s. $$ Knowing past information, zero profit, i.e. fair game.","title":"difference characterization"},{"location":"measure/martingale/def/#product-mg","text":"indep. Y_n\\geq 0 Y_n\\geq 0 . M_n=\\prod^nY_i M_n=\\prod^nY_i , E[M_{n+1}|\\mathcal{F}_n^Y]=M_nE[Y_{n+1}]=M_n \\Leftrightarrow E[Y_n]=1,\\forall n E[M_{n+1}|\\mathcal{F}_n^Y]=M_nE[Y_{n+1}]=M_n \\Leftrightarrow E[Y_n]=1,\\forall n or general condition E[Y_{n+1}|\\mathcal{F}_n^Y]=1 E[Y_{n+1}|\\mathcal{F}_n^Y]=1 a.s.","title":"product MG"},{"location":"measure/martingale/def/#sub-mg","text":"E[X_{n+1}|\\mathcal{F}_n]\\geq X_n, \\forall n, a.s. E[X_{n+1}|\\mathcal{F}_n]\\geq X_n, \\forall n, a.s. Implicitly used for sub-MG, sup-MG or MG.","title":"sub-MG"},{"location":"measure/martingale/def/#strong-mg","text":"MG iff E[X_n|\\mathcal{F}_\\tau]=X_\\tau, \\forall\\tau\\leq n,\\forall n E[X_n|\\mathcal{F}_\\tau]=X_\\tau, \\forall\\tau\\leq n,\\forall n","title":"strong MG"},{"location":"measure/martingale/def/#local-mg","text":"","title":"local MG"},{"location":"measure/martingale/def/#stopping-time","text":"A R.V. \\tau \\tau values \\mathbb{N}\\cup\\infty \\mathbb{N}\\cup\\infty for filtration \\{\\mathcal{F}_n\\} \\{\\mathcal{F}_n\\} , if \\{\\omega:\\tau(\\omega)\\leq n\\}\\in\\mathcal{F}_n,\\forall n \\{\\omega:\\tau(\\omega)\\leq n\\}\\in\\mathcal{F}_n,\\forall n","title":"stopping time"},{"location":"measure/martingale/def/#stopped-at","text":"X_{n\\wedge\\tau}(\\omega) = \\begin{cases}X_n(\\omega), n\\leq\\tau(\\omega) \\\\\\\\ X_{\\tau(\\omega)}(\\omega), n>\\tau(\\omega)\\end{cases} X_{n\\wedge\\tau}(\\omega) = \\begin{cases}X_n(\\omega), n\\leq\\tau(\\omega) \\\\\\\\ X_{\\tau(\\omega)}(\\omega), n>\\tau(\\omega)\\end{cases}","title":"stopped at"},{"location":"measure/martingale/def/#stopped-sigmasigma-algebra","text":"\\mathcal{F}_\\tau:=\\{A\\in\\mathcal{F}:A\\cap\\{\\omega:\\tau(\\omega)\\leq n\\}\\in\\mathcal{F}_n,\\forall n\\} \\mathcal{F}_\\tau:=\\{A\\in\\mathcal{F}:A\\cap\\{\\omega:\\tau(\\omega)\\leq n\\}\\in\\mathcal{F}_n,\\forall n\\}","title":"stopped \\sigma\\sigma-algebra"},{"location":"measure/martingale/def/#pridictable","text":"V_n\\in m\\mathcal{F}_{n-1},\\forall n V_n\\in m\\mathcal{F}_{n-1},\\forall n","title":"pridictable"},{"location":"measure/martingale/def/#mg-transform","text":"Y_n = \\sum^n V_i(X_i-X_{i-1}) Y_n = \\sum^n V_i(X_i-X_{i-1})","title":"MG transform"},{"location":"measure/martingale/def/#up-crossings","text":"number of up-crossings U_n[a,b] U_n[a,b] , largest l, (s_i,t_i)_l l, (s_i,t_i)_l s.t. X_s<a<b<X_t, s_1<t_1<s_2<\\cdots X_s<a<b<X_t, s_1<t_1<s_2<\\cdots","title":"up-crossings"},{"location":"measure/martingale/exc/","text":"Exchangeable \u00b6 A \\sigma \\sigma -algebra \\mathcal{E}_m \\mathcal{E}_m , denote events are invariant under first m m permutation, i.e. A\\in\\mathcal{E}_m A\\in\\mathcal{E}_m , then (\\omega_{\\pi(1)},\\cdots,\\omega_{\\pi(m)},\\omega_{m+1},\\cdots)\\in A,\\forall \\pi, \\forall(\\omega)\\in A (\\omega_{\\pi(1)},\\cdots,\\omega_{\\pi(m)},\\omega_{m+1},\\cdots)\\in A,\\forall \\pi, \\forall(\\omega)\\in A Let \\mathcal{E}=\\bigcap_m\\mathcal{E}_m \\mathcal{E}=\\bigcap_m\\mathcal{E}_m be exchangeble, denoted invariant under all finite permutation. i.e. for R.V.s, Symmetric law, \\xi_{[m]} \\overset{d}= \\xi_{\\pi} \\xi_{[m]} \\overset{d}= \\xi_{\\pi} . Hewitt-Savage 0-1 law \u00b6 The exchangeable \\sigma \\sigma -algebra \\mathcal{E} \\mathcal{E} of i.i.d \\xi \\xi , is P-trivial. Intuitively, within or without F_n F_n , are identical \\mathcal{E} \\mathcal{E} , thus independence and lemma . De Finetti\u2019s theorem \u00b6 Exchangeable \\xi \\xi , are P-m.i.i.d conditional on \\mathcal{E} \\mathcal{E} .","title":"Exchangeable"},{"location":"measure/martingale/exc/#exchangeable","text":"A \\sigma \\sigma -algebra \\mathcal{E}_m \\mathcal{E}_m , denote events are invariant under first m m permutation, i.e. A\\in\\mathcal{E}_m A\\in\\mathcal{E}_m , then (\\omega_{\\pi(1)},\\cdots,\\omega_{\\pi(m)},\\omega_{m+1},\\cdots)\\in A,\\forall \\pi, \\forall(\\omega)\\in A (\\omega_{\\pi(1)},\\cdots,\\omega_{\\pi(m)},\\omega_{m+1},\\cdots)\\in A,\\forall \\pi, \\forall(\\omega)\\in A Let \\mathcal{E}=\\bigcap_m\\mathcal{E}_m \\mathcal{E}=\\bigcap_m\\mathcal{E}_m be exchangeble, denoted invariant under all finite permutation. i.e. for R.V.s, Symmetric law, \\xi_{[m]} \\overset{d}= \\xi_{\\pi} \\xi_{[m]} \\overset{d}= \\xi_{\\pi} .","title":"Exchangeable"},{"location":"measure/martingale/exc/#hewitt-savage-0-1-law","text":"The exchangeable \\sigma \\sigma -algebra \\mathcal{E} \\mathcal{E} of i.i.d \\xi \\xi , is P-trivial. Intuitively, within or without F_n F_n , are identical \\mathcal{E} \\mathcal{E} , thus independence and lemma .","title":"Hewitt-Savage 0-1 law"},{"location":"measure/martingale/exc/#de-finettis-theorem","text":"Exchangeable \\xi \\xi , are P-m.i.i.d conditional on \\mathcal{E} \\mathcal{E} .","title":"De Finetti\u2019s theorem"},{"location":"measure/martingale/ost/","text":"Doob's OST \u00b6 X_n=Y_n+V_n X_n=Y_n+V_n , that sub-MG Y_n,V_n Y_n,V_n s.t. V_n\\leq 0 V_n\\leq 0 , Y_{n\\wedge\\tau} Y_{n\\wedge\\tau} is U.I., then EX_0\\leq EX_\\theta \\leq EX_\\tau, \\theta\\leq\\tau EX_0\\leq EX_\\theta \\leq EX_\\tau, \\theta\\leq\\tau V_n V_n represents some tax, e.g. house's edge in casino. For main part Y_{n\\wedge\\tau} Y_{n\\wedge\\tau} U.I. if one of below hold E\\tau <\\infty E\\tau <\\infty , E[|Y_{n+1}-Y_n|\\mathcal{F}_n] \\leq c E[|Y_{n+1}-Y_n|\\mathcal{F}_n] \\leq c a.s. Y_nI_{\\tau>n} Y_nI_{\\tau>n} are U.I., Y_\\tau I_{\\tau<\\infty} Y_\\tau I_{\\tau<\\infty} is I. Y_n Y_n is U.I. classic for MG \u00b6 EX_\\tau = EX_0 EX_\\tau = EX_0","title":"Doob's optional stopping theorem"},{"location":"measure/martingale/ost/#doobs-ost","text":"X_n=Y_n+V_n X_n=Y_n+V_n , that sub-MG Y_n,V_n Y_n,V_n s.t. V_n\\leq 0 V_n\\leq 0 , Y_{n\\wedge\\tau} Y_{n\\wedge\\tau} is U.I., then EX_0\\leq EX_\\theta \\leq EX_\\tau, \\theta\\leq\\tau EX_0\\leq EX_\\theta \\leq EX_\\tau, \\theta\\leq\\tau V_n V_n represents some tax, e.g. house's edge in casino. For main part Y_{n\\wedge\\tau} Y_{n\\wedge\\tau} U.I. if one of below hold E\\tau <\\infty E\\tau <\\infty , E[|Y_{n+1}-Y_n|\\mathcal{F}_n] \\leq c E[|Y_{n+1}-Y_n|\\mathcal{F}_n] \\leq c a.s. Y_nI_{\\tau>n} Y_nI_{\\tau>n} are U.I., Y_\\tau I_{\\tau<\\infty} Y_\\tau I_{\\tau<\\infty} is I. Y_n Y_n is U.I.","title":"Doob's OST"},{"location":"measure/martingale/ost/#classic-for-mg","text":"EX_\\tau = EX_0 EX_\\tau = EX_0","title":"classic for MG"},{"location":"measure/martingale/rev/","text":"RMG \u00b6 F_n\\downarrow F_{-\\infty}=\\bigcap_{n\\leq 0}F_n F_n\\downarrow F_{-\\infty}=\\bigcap_{n\\leq 0}F_n . And results don't involve n\\rightarrow\\infty n\\rightarrow\\infty hold. L\u00e9vy\u2019s downward theorem \u00b6 RMG iff E[X_0|F_n]=X_n, \\forall n\\leq 0 E[X_0|F_n]=X_n, \\forall n\\leq 0 . Furthermore, E[X_0|F_n]\\xrightarrow{a.s., L_1} E[X_0|F_{-\\infty}] E[X_0|F_n]\\xrightarrow{a.s., L_1} E[X_0|F_{-\\infty}] upward tells that gradually gain information converge to R.V., downward tells that gradually loss information converge to R.V. A proof of strong LLN \u00b6 Let X_{-n} = n^{-1}\\sum^n\\xi_i X_{-n} = n^{-1}\\sum^n\\xi_i , then according to linearity and i.i.d. with permutation, get that E[\\xi_1| X_{-n}] = X_{-n} E[\\xi_1| X_{-n}] = X_{-n} Thus RMG, which implies converge to X_{-\\infty}=E[\\xi_1|F_{-\\infty}] X_{-\\infty}=E[\\xi_1|F_{-\\infty}] , thus E[X_{-\\infty}]=E[\\xi_1] E[X_{-\\infty}]=E[\\xi_1] . Note X_{-\\infty} X_{-\\infty} remains even eliminate finite, i.e. \\forall k \\forall k X_{-\\infty} = \\limsup_n n^{-1}\\sum_{i=k}^n \\xi_i X_{-\\infty} = \\limsup_n n^{-1}\\sum_{i=k}^n \\xi_i Thus X_{-\\infty}\\in mT X_{-\\infty}\\in mT , recall Kolmogorov's 0-1 law, tail is trivial, that is X_{-\\infty}\\xrightarrow{a.s.}\\mu.\\square X_{-\\infty}\\xrightarrow{a.s.}\\mu.\\square","title":"Reversed martingale"},{"location":"measure/martingale/rev/#rmg","text":"F_n\\downarrow F_{-\\infty}=\\bigcap_{n\\leq 0}F_n F_n\\downarrow F_{-\\infty}=\\bigcap_{n\\leq 0}F_n . And results don't involve n\\rightarrow\\infty n\\rightarrow\\infty hold.","title":"RMG"},{"location":"measure/martingale/rev/#levys-downward-theorem","text":"RMG iff E[X_0|F_n]=X_n, \\forall n\\leq 0 E[X_0|F_n]=X_n, \\forall n\\leq 0 . Furthermore, E[X_0|F_n]\\xrightarrow{a.s., L_1} E[X_0|F_{-\\infty}] E[X_0|F_n]\\xrightarrow{a.s., L_1} E[X_0|F_{-\\infty}] upward tells that gradually gain information converge to R.V., downward tells that gradually loss information converge to R.V.","title":"L\u00e9vy\u2019s downward theorem"},{"location":"measure/martingale/rev/#a-proof-of-strong-lln","text":"Let X_{-n} = n^{-1}\\sum^n\\xi_i X_{-n} = n^{-1}\\sum^n\\xi_i , then according to linearity and i.i.d. with permutation, get that E[\\xi_1| X_{-n}] = X_{-n} E[\\xi_1| X_{-n}] = X_{-n} Thus RMG, which implies converge to X_{-\\infty}=E[\\xi_1|F_{-\\infty}] X_{-\\infty}=E[\\xi_1|F_{-\\infty}] , thus E[X_{-\\infty}]=E[\\xi_1] E[X_{-\\infty}]=E[\\xi_1] . Note X_{-\\infty} X_{-\\infty} remains even eliminate finite, i.e. \\forall k \\forall k X_{-\\infty} = \\limsup_n n^{-1}\\sum_{i=k}^n \\xi_i X_{-\\infty} = \\limsup_n n^{-1}\\sum_{i=k}^n \\xi_i Thus X_{-\\infty}\\in mT X_{-\\infty}\\in mT , recall Kolmogorov's 0-1 law, tail is trivial, that is X_{-\\infty}\\xrightarrow{a.s.}\\mu.\\square X_{-\\infty}\\xrightarrow{a.s.}\\mu.\\square","title":"A proof of strong LLN"},{"location":"models/","text":"Models, schemes, exercises.","title":"Intro"},{"location":"models/ballot/","text":"Description \u00b6 classic \u00b6 Given total voted a\\leq b a\\leq b , let n=a+b, s=b-a n=a+b, s=b-a , the probability B leads A through whole counting is P(A<B, \\forall i\\in[n]) = \\dfrac{s}{n} P(A<B, \\forall i\\in[n]) = \\dfrac{s}{n} catalan \u00b6 Interpret voting B/A as moving right/up one step in lattice, then event is corresponding to not hit diagonal. (catalan is allowed tie) SRW \u00b6 Interpret voting B/A as +1 +1 / -1 -1 , let z=\\inf\\{t>0:S_t=0\\} z=\\inf\\{t>0:S_t=0\\} , then probability denoted as P(z>n|S_n=s) P(z>n|S_n=s) Proofs \u00b6 classic reflection \u00b6 The bad votings can be separated to \\xi_1=1 \\xi_1=1 or -1 -1 , which two groups are bijection, by fliping \\xi_i \\xi_i for i\\leq z i\\leq z . And note all start with -1 -1 are bad, regarding to likelihood of p_A=a/n p_A=a/n , we get the answer P = 1-2p_A=\\dfrac{s}{n} P = 1-2p_A=\\dfrac{s}{n} \\square \\square SRW \u00b6 Let \\tau_s:=\\inf\\{t\\geq 0: S_t=s\\} \\tau_s:=\\inf\\{t\\geq 0: S_t=s\\} , by central rotation to path, we get another bijection which imply P(\\tau_s = n | S_n=s) = P(z>n | S_n=s) P(\\tau_s = n | S_n=s) = P(z>n | S_n=s) Note \\{X_n = n^{-1}S_n\\} \\{X_n = n^{-1}S_n\\} is RMG, let \\theta = \\sup\\{2\\leq t\\leq n: S_t=0\\} \\vee 1 \\theta = \\sup\\{2\\leq t\\leq n: S_t=0\\} \\vee 1 , which is valid stopping time in RMG, notice that X_\\theta = \\begin{cases} 0, \\theta > 1 \\\\\\\\ 1,\\theta=1\\end{cases} X_\\theta = \\begin{cases} 0, \\theta > 1 \\\\\\\\ 1,\\theta=1\\end{cases} thus E[X_\\theta|F_n]=P(\\theta=1|F_n) E[X_\\theta|F_n]=P(\\theta=1|F_n) , and \\{\\theta = 1\\} \\{\\theta = 1\\} is indeed same event above. Recall Doob's OST, P = E[X_\\theta|F_n] = X_n = \\dfrac{s}{n} P = E[X_\\theta|F_n] = X_n = \\dfrac{s}{n} Remark. \\theta \\theta is indeed rotation of \\tau_s \\tau_s , in this problem, \\inf,\\sup \\inf,\\sup does not affect bijection, we choose which is measurable for MG fitraction requirement. \\square \\square Collorary \u00b6 This give us explict formula of hitting probability in Gambler's ruin, for k\\geq 0 k\\geq 0 P(\\tau_b = b+2k) = \\dfrac{b}{b+2k} P(S_n=b) = \\dfrac{b}{b+2k} \\dbinom{b+2k}{k} p^{k+b} q^{k} P(\\tau_b = b+2k) = \\dfrac{b}{b+2k} P(S_n=b) = \\dfrac{b}{b+2k} \\dbinom{b+2k}{k} p^{k+b} q^{k}","title":"Bertrand's ballot"},{"location":"models/ballot/#description","text":"","title":"Description"},{"location":"models/ballot/#classic","text":"Given total voted a\\leq b a\\leq b , let n=a+b, s=b-a n=a+b, s=b-a , the probability B leads A through whole counting is P(A<B, \\forall i\\in[n]) = \\dfrac{s}{n} P(A<B, \\forall i\\in[n]) = \\dfrac{s}{n}","title":"classic"},{"location":"models/ballot/#catalan","text":"Interpret voting B/A as moving right/up one step in lattice, then event is corresponding to not hit diagonal. (catalan is allowed tie)","title":"catalan"},{"location":"models/ballot/#srw","text":"Interpret voting B/A as +1 +1 / -1 -1 , let z=\\inf\\{t>0:S_t=0\\} z=\\inf\\{t>0:S_t=0\\} , then probability denoted as P(z>n|S_n=s) P(z>n|S_n=s)","title":"SRW"},{"location":"models/ballot/#proofs","text":"","title":"Proofs"},{"location":"models/ballot/#classic-reflection","text":"The bad votings can be separated to \\xi_1=1 \\xi_1=1 or -1 -1 , which two groups are bijection, by fliping \\xi_i \\xi_i for i\\leq z i\\leq z . And note all start with -1 -1 are bad, regarding to likelihood of p_A=a/n p_A=a/n , we get the answer P = 1-2p_A=\\dfrac{s}{n} P = 1-2p_A=\\dfrac{s}{n} \\square \\square","title":"classic reflection"},{"location":"models/ballot/#srw_1","text":"Let \\tau_s:=\\inf\\{t\\geq 0: S_t=s\\} \\tau_s:=\\inf\\{t\\geq 0: S_t=s\\} , by central rotation to path, we get another bijection which imply P(\\tau_s = n | S_n=s) = P(z>n | S_n=s) P(\\tau_s = n | S_n=s) = P(z>n | S_n=s) Note \\{X_n = n^{-1}S_n\\} \\{X_n = n^{-1}S_n\\} is RMG, let \\theta = \\sup\\{2\\leq t\\leq n: S_t=0\\} \\vee 1 \\theta = \\sup\\{2\\leq t\\leq n: S_t=0\\} \\vee 1 , which is valid stopping time in RMG, notice that X_\\theta = \\begin{cases} 0, \\theta > 1 \\\\\\\\ 1,\\theta=1\\end{cases} X_\\theta = \\begin{cases} 0, \\theta > 1 \\\\\\\\ 1,\\theta=1\\end{cases} thus E[X_\\theta|F_n]=P(\\theta=1|F_n) E[X_\\theta|F_n]=P(\\theta=1|F_n) , and \\{\\theta = 1\\} \\{\\theta = 1\\} is indeed same event above. Recall Doob's OST, P = E[X_\\theta|F_n] = X_n = \\dfrac{s}{n} P = E[X_\\theta|F_n] = X_n = \\dfrac{s}{n} Remark. \\theta \\theta is indeed rotation of \\tau_s \\tau_s , in this problem, \\inf,\\sup \\inf,\\sup does not affect bijection, we choose which is measurable for MG fitraction requirement. \\square \\square","title":"SRW"},{"location":"models/ballot/#collorary","text":"This give us explict formula of hitting probability in Gambler's ruin, for k\\geq 0 k\\geq 0 P(\\tau_b = b+2k) = \\dfrac{b}{b+2k} P(S_n=b) = \\dfrac{b}{b+2k} \\dbinom{b+2k}{k} p^{k+b} q^{k} P(\\tau_b = b+2k) = \\dfrac{b}{b+2k} P(S_n=b) = \\dfrac{b}{b+2k} \\dbinom{b+2k}{k} p^{k+b} q^{k}","title":"Collorary"},{"location":"models/gamblers_ruin/","text":"Description \u00b6 SRW p,S_n=\\sum\\xi_i p,S_n=\\sum\\xi_i . Fix a,b\\in \\mathbb{N}^+ a,b\\in \\mathbb{N}^+ , the probability hit -a -a before b b , called ruin probability, which is r = \\begin{cases} \\dfrac{e^{\\lambda b} - 1}{e^{\\lambda b} - e^{-\\lambda a}}, \\lambda = \\log\\dfrac{1-p}{p}\\neq 0 \\\\\\\\ \\dfrac{b}{a+b}, p=\\dfrac{1}{2} \\end{cases} r = \\begin{cases} \\dfrac{e^{\\lambda b} - 1}{e^{\\lambda b} - e^{-\\lambda a}}, \\lambda = \\log\\dfrac{1-p}{p}\\neq 0 \\\\\\\\ \\dfrac{b}{a+b}, p=\\dfrac{1}{2} \\end{cases} Proof \u00b6 Let stopping time \\tau_{a,b} = \\inf\\{n: S_n\\leq -a, or\\ S_n\\geq b\\} \\tau_{a,b} = \\inf\\{n: S_n\\leq -a, or\\ S_n\\geq b\\} Which is a.s. finite, since S_+=(S_n+n)/2 \\sim \\text{Binomial}(n,p) S_+=(S_n+n)/2 \\sim \\text{Binomial}(n,p) , recall stirling approximation, each point probability tends to 0. Then construct product MG that M_n = \\prod_i^n e^{\\lambda \\xi_i} M_n = \\prod_i^n e^{\\lambda \\xi_i} Recall Doob's optional stopping theorem, that r e^{-\\lambda a} + (1-r)e^{\\lambda b}=1 r e^{-\\lambda a} + (1-r)e^{\\lambda b}=1 For p=1/2 p=1/2 , note S_n S_n is MG, that r(-a) + (1-r)b = 0 r(-a) + (1-r)b = 0 \\square \\square Properties \u00b6 expectation \u00b6 Recall Wald's identities, E\\tau_{a,b} = \\dfrac{ES_\\tau}{E\\xi} = \\dfrac{b-r(a+b)}{2p-1} E\\tau_{a,b} = \\dfrac{ES_\\tau}{E\\xi} = \\dfrac{b-r(a+b)}{2p-1} drift up \u00b6 let \\tau_b = \\inf\\{n:S_n\\geq b\\} \\tau_b = \\inf\\{n:S_n\\geq b\\} , that \\tau_{a,b}\\uparrow \\tau_b \\tau_{a,b}\\uparrow \\tau_b as a\\uparrow\\infty a\\uparrow\\infty . If p\\geq 1/2 p\\geq 1/2 , then E\\tau_b = \\dfrac{b}{2p-1} E\\tau_b = \\dfrac{b}{2p-1} Since ra\\rightarrow 0 ra\\rightarrow 0 . \\tau_b<\\infty \\tau_b<\\infty a.s. Proof \u00b6 p>1/2 p>1/2 is trivial since E\\tau_b<\\infty E\\tau_b<\\infty . When sym-SRW, recall reflection principle, P(\\sup_n S_n\\geq b)\\rightarrow 1 P(\\sup_n S_n\\geq b)\\rightarrow 1 i.e. P(\\tau_b = \\infty) = 0 P(\\tau_b = \\infty) = 0 \\square \\square drift down \u00b6 If p<1/2 p<1/2 , P(\\tau_b < \\infty) = e^{-\\lambda b} P(\\tau_b < \\infty) = e^{-\\lambda b} Proof \u00b6 Note \\tau_{a,b} \\tau_{a,b} a.s. finite, and a\\leq \\tau_{-a} a\\leq \\tau_{-a} , thus P(\\tau_b < a) \\leq P(\\tau_b < \\tau_{-a})\\leq P(\\tau_b < \\infty) P(\\tau_b < a) \\leq P(\\tau_b < \\tau_{-a})\\leq P(\\tau_b < \\infty) which implies P(\\tau_b < \\tau_{-a})\\rightarrow P(\\tau_b < \\infty) P(\\tau_b < \\tau_{-a})\\rightarrow P(\\tau_b < \\infty) as a\\rightarrow\\infty a\\rightarrow\\infty . Then P(\\tau_b < \\infty) = 1-r|_{a\\rightarrow\\infty}= e^{-\\lambda b} P(\\tau_b < \\infty) = 1-r|_{a\\rightarrow\\infty}= e^{-\\lambda b} \\square \\square Let Z = 1+\\max_{n\\geq 0} S_n Z = 1+\\max_{n\\geq 0} S_n , then Z \\sim \\text{Geometric}(p=1-e^{-\\lambda}) Z \\sim \\text{Geometric}(p=1-e^{-\\lambda}) Proof \u00b6 Note \\{\\tau_b<\\infty\\} \\{\\tau_b<\\infty\\} iff \\{Z>b\\} \\{Z>b\\} , that P(Z=b) = e^{-\\lambda (b-1)} - e^{-\\lambda b} = (1-p)^{(b-1)}p P(Z=b) = e^{-\\lambda (b-1)} - e^{-\\lambda b} = (1-p)^{(b-1)}p \\square \\square","title":"Gambler's ruin"},{"location":"models/gamblers_ruin/#description","text":"SRW p,S_n=\\sum\\xi_i p,S_n=\\sum\\xi_i . Fix a,b\\in \\mathbb{N}^+ a,b\\in \\mathbb{N}^+ , the probability hit -a -a before b b , called ruin probability, which is r = \\begin{cases} \\dfrac{e^{\\lambda b} - 1}{e^{\\lambda b} - e^{-\\lambda a}}, \\lambda = \\log\\dfrac{1-p}{p}\\neq 0 \\\\\\\\ \\dfrac{b}{a+b}, p=\\dfrac{1}{2} \\end{cases} r = \\begin{cases} \\dfrac{e^{\\lambda b} - 1}{e^{\\lambda b} - e^{-\\lambda a}}, \\lambda = \\log\\dfrac{1-p}{p}\\neq 0 \\\\\\\\ \\dfrac{b}{a+b}, p=\\dfrac{1}{2} \\end{cases}","title":"Description"},{"location":"models/gamblers_ruin/#proof","text":"Let stopping time \\tau_{a,b} = \\inf\\{n: S_n\\leq -a, or\\ S_n\\geq b\\} \\tau_{a,b} = \\inf\\{n: S_n\\leq -a, or\\ S_n\\geq b\\} Which is a.s. finite, since S_+=(S_n+n)/2 \\sim \\text{Binomial}(n,p) S_+=(S_n+n)/2 \\sim \\text{Binomial}(n,p) , recall stirling approximation, each point probability tends to 0. Then construct product MG that M_n = \\prod_i^n e^{\\lambda \\xi_i} M_n = \\prod_i^n e^{\\lambda \\xi_i} Recall Doob's optional stopping theorem, that r e^{-\\lambda a} + (1-r)e^{\\lambda b}=1 r e^{-\\lambda a} + (1-r)e^{\\lambda b}=1 For p=1/2 p=1/2 , note S_n S_n is MG, that r(-a) + (1-r)b = 0 r(-a) + (1-r)b = 0 \\square \\square","title":"Proof"},{"location":"models/gamblers_ruin/#properties","text":"","title":"Properties"},{"location":"models/gamblers_ruin/#expectation","text":"Recall Wald's identities, E\\tau_{a,b} = \\dfrac{ES_\\tau}{E\\xi} = \\dfrac{b-r(a+b)}{2p-1} E\\tau_{a,b} = \\dfrac{ES_\\tau}{E\\xi} = \\dfrac{b-r(a+b)}{2p-1}","title":"expectation"},{"location":"models/gamblers_ruin/#drift-up","text":"let \\tau_b = \\inf\\{n:S_n\\geq b\\} \\tau_b = \\inf\\{n:S_n\\geq b\\} , that \\tau_{a,b}\\uparrow \\tau_b \\tau_{a,b}\\uparrow \\tau_b as a\\uparrow\\infty a\\uparrow\\infty . If p\\geq 1/2 p\\geq 1/2 , then E\\tau_b = \\dfrac{b}{2p-1} E\\tau_b = \\dfrac{b}{2p-1} Since ra\\rightarrow 0 ra\\rightarrow 0 . \\tau_b<\\infty \\tau_b<\\infty a.s.","title":"drift up"},{"location":"models/gamblers_ruin/#proof_1","text":"p>1/2 p>1/2 is trivial since E\\tau_b<\\infty E\\tau_b<\\infty . When sym-SRW, recall reflection principle, P(\\sup_n S_n\\geq b)\\rightarrow 1 P(\\sup_n S_n\\geq b)\\rightarrow 1 i.e. P(\\tau_b = \\infty) = 0 P(\\tau_b = \\infty) = 0 \\square \\square","title":"Proof"},{"location":"models/gamblers_ruin/#drift-down","text":"If p<1/2 p<1/2 , P(\\tau_b < \\infty) = e^{-\\lambda b} P(\\tau_b < \\infty) = e^{-\\lambda b}","title":"drift down"},{"location":"models/gamblers_ruin/#proof_2","text":"Note \\tau_{a,b} \\tau_{a,b} a.s. finite, and a\\leq \\tau_{-a} a\\leq \\tau_{-a} , thus P(\\tau_b < a) \\leq P(\\tau_b < \\tau_{-a})\\leq P(\\tau_b < \\infty) P(\\tau_b < a) \\leq P(\\tau_b < \\tau_{-a})\\leq P(\\tau_b < \\infty) which implies P(\\tau_b < \\tau_{-a})\\rightarrow P(\\tau_b < \\infty) P(\\tau_b < \\tau_{-a})\\rightarrow P(\\tau_b < \\infty) as a\\rightarrow\\infty a\\rightarrow\\infty . Then P(\\tau_b < \\infty) = 1-r|_{a\\rightarrow\\infty}= e^{-\\lambda b} P(\\tau_b < \\infty) = 1-r|_{a\\rightarrow\\infty}= e^{-\\lambda b} \\square \\square Let Z = 1+\\max_{n\\geq 0} S_n Z = 1+\\max_{n\\geq 0} S_n , then Z \\sim \\text{Geometric}(p=1-e^{-\\lambda}) Z \\sim \\text{Geometric}(p=1-e^{-\\lambda})","title":"Proof"},{"location":"models/gamblers_ruin/#proof_3","text":"Note \\{\\tau_b<\\infty\\} \\{\\tau_b<\\infty\\} iff \\{Z>b\\} \\{Z>b\\} , that P(Z=b) = e^{-\\lambda (b-1)} - e^{-\\lambda b} = (1-p)^{(b-1)}p P(Z=b) = e^{-\\lambda (b-1)} - e^{-\\lambda b} = (1-p)^{(b-1)}p \\square \\square","title":"Proof"},{"location":"models/polya_urn/","text":"Description \u00b6 Initially contain r r red balls and b b blue balls, after k k -th observation, add c_k c_k balls of same color into the urn. Let M_n=R_n/N_n M_n=R_n/N_n be fraction of reds. Thus E[R_{n+1}|\\mathcal{F}_n^M] = R_n + c_n M_n = N_{n+1}M_n \\\\\\\\ \\Rightarrow E[M_{n+1}|\\mathcal{F}_n^M] = M_n E[R_{n+1}|\\mathcal{F}_n^M] = R_n + c_n M_n = N_{n+1}M_n \\\\\\\\ \\Rightarrow E[M_{n+1}|\\mathcal{F}_n^M] = M_n i.e. M_n M_n is uniformly bounded MG, which converges a.s. and L^p L^p , by DCT and Doob's L^p L^p . add constant \u00b6 Only information we care is number of time observated reds in n n turns, denoted as X_n X_n , thus P(X_n = k) = \\dbinom{n}{k} \\dfrac{ r^{(c,k)} b^{(c,n-k)}}{(r+b)^{(c,n)}} P(X_n = k) = \\dbinom{n}{k} \\dfrac{ r^{(c,k)} b^{(c,n-k)}}{(r+b)^{(c,n)}} where x^{(c,k)} = \\prod_{i=0}^{k-1} (x+ci) x^{(c,k)} = \\prod_{i=0}^{k-1} (x+ci) . Let \\alpha=r/c,\\beta=b/c,p=r/(r+b) \\alpha=r/c,\\beta=b/c,p=r/(r+b) , use rising factorial we can rewrite case c>0 c>0 , that P(X_n = k) = \\dbinom{n}{k} \\dfrac{ \\alpha^{\\overline{k}} \\beta^{\\overline{n-k}}}{(\\alpha + \\beta)^{\\overline{n}}} P(X_n = k) = \\dbinom{n}{k} \\dfrac{ \\alpha^{\\overline{k}} \\beta^{\\overline{n-k}}}{(\\alpha + \\beta)^{\\overline{n}}} c = 0 c = 0 \u00b6 X_n\\sim \\text{Bin}(n,p) X_n\\sim \\text{Bin}(n,p) c = -1 c = -1 \u00b6 X_n\\sim \\text{Hypergeometric}(r+b, r, n) X_n\\sim \\text{Hypergeometric}(r+b, r, n) c \\geq 1 c \\geq 1 \u00b6 X_n\\sim \\text{Beta-binomial}(n,\\alpha,\\beta) X_n\\sim \\text{Beta-binomial}(n,\\alpha,\\beta) Proof \u00b6 \\begin{align} \\dfrac{ \\alpha^{\\overline{k}} \\beta^{\\overline{n-k}}}{(\\alpha + \\beta)^{\\overline{n}}} &= \\dfrac{\\Gamma(\\alpha+k)/\\Gamma(\\alpha) \\cdot \\Gamma(\\beta+n-k)/\\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta+n)/\\Gamma(\\alpha+\\beta)} \\\\\\\\ &= \\dfrac{B(k+\\alpha,n-k+\\beta)}{B(\\alpha,\\beta)} \\end{align} \\begin{align} \\dfrac{ \\alpha^{\\overline{k}} \\beta^{\\overline{n-k}}}{(\\alpha + \\beta)^{\\overline{n}}} &= \\dfrac{\\Gamma(\\alpha+k)/\\Gamma(\\alpha) \\cdot \\Gamma(\\beta+n-k)/\\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta+n)/\\Gamma(\\alpha+\\beta)} \\\\\\\\ &= \\dfrac{B(k+\\alpha,n-k+\\beta)}{B(\\alpha,\\beta)} \\end{align} \\square \\square limit \u00b6 M_\\infty \\sim \\text{Beta}(\\alpha,\\beta) M_\\infty \\sim \\text{Beta}(\\alpha,\\beta) proof \u00b6 \\begin{align} P(X_n=k) &= \\dfrac{\\Gamma(n+1)}{\\Gamma(k+1)\\Gamma(n-k+1)}\\dfrac{B(k+\\alpha,n-k+\\beta)}{B(\\alpha,\\beta)} \\\\\\\\ &= \\dfrac{1}{B(\\alpha,\\beta)} \\dfrac{k^{(\\alpha-1)} (n-k)^{(\\beta-1)}}{n^{(\\alpha+\\beta-1)}} \\end{align} \\begin{align} P(X_n=k) &= \\dfrac{\\Gamma(n+1)}{\\Gamma(k+1)\\Gamma(n-k+1)}\\dfrac{B(k+\\alpha,n-k+\\beta)}{B(\\alpha,\\beta)} \\\\\\\\ &= \\dfrac{1}{B(\\alpha,\\beta)} \\dfrac{k^{(\\alpha-1)} (n-k)^{(\\beta-1)}}{n^{(\\alpha+\\beta-1)}} \\end{align} note k^{(a)}\\rightarrow k^a k^{(a)}\\rightarrow k^a as k\\rightarrow\\infty k\\rightarrow\\infty , thus dP = \\dfrac{1}{B(\\alpha,\\beta)} x^{\\alpha-1}(1-x)^{\\beta-1}dx dP = \\dfrac{1}{B(\\alpha,\\beta)} x^{\\alpha-1}(1-x)^{\\beta-1}dx \\square \\square uniform \u00b6 In particular, \\alpha=\\beta=1 \\alpha=\\beta=1 , then M_\\infty\\sim U(0,1] M_\\infty\\sim U(0,1] . Recall Doob's maximal inequality, that P(\\sup M_n \\geq 3/4) \\leq 2/3 P(\\sup M_n \\geq 3/4) \\leq 2/3 Bernard Friedman\u2019s urn \u00b6 Add additional d_k d_k balls of opposite color. If c_k,d_k c_k,d_k uniformly bounded, r+b>0 r+b>0 , then M_n \\xrightarrow{a.s.}\\dfrac{1}{2} M_n \\xrightarrow{a.s.}\\dfrac{1}{2}","title":"P\u00f3lya's urn"},{"location":"models/polya_urn/#description","text":"Initially contain r r red balls and b b blue balls, after k k -th observation, add c_k c_k balls of same color into the urn. Let M_n=R_n/N_n M_n=R_n/N_n be fraction of reds. Thus E[R_{n+1}|\\mathcal{F}_n^M] = R_n + c_n M_n = N_{n+1}M_n \\\\\\\\ \\Rightarrow E[M_{n+1}|\\mathcal{F}_n^M] = M_n E[R_{n+1}|\\mathcal{F}_n^M] = R_n + c_n M_n = N_{n+1}M_n \\\\\\\\ \\Rightarrow E[M_{n+1}|\\mathcal{F}_n^M] = M_n i.e. M_n M_n is uniformly bounded MG, which converges a.s. and L^p L^p , by DCT and Doob's L^p L^p .","title":"Description"},{"location":"models/polya_urn/#add-constant","text":"Only information we care is number of time observated reds in n n turns, denoted as X_n X_n , thus P(X_n = k) = \\dbinom{n}{k} \\dfrac{ r^{(c,k)} b^{(c,n-k)}}{(r+b)^{(c,n)}} P(X_n = k) = \\dbinom{n}{k} \\dfrac{ r^{(c,k)} b^{(c,n-k)}}{(r+b)^{(c,n)}} where x^{(c,k)} = \\prod_{i=0}^{k-1} (x+ci) x^{(c,k)} = \\prod_{i=0}^{k-1} (x+ci) . Let \\alpha=r/c,\\beta=b/c,p=r/(r+b) \\alpha=r/c,\\beta=b/c,p=r/(r+b) , use rising factorial we can rewrite case c>0 c>0 , that P(X_n = k) = \\dbinom{n}{k} \\dfrac{ \\alpha^{\\overline{k}} \\beta^{\\overline{n-k}}}{(\\alpha + \\beta)^{\\overline{n}}} P(X_n = k) = \\dbinom{n}{k} \\dfrac{ \\alpha^{\\overline{k}} \\beta^{\\overline{n-k}}}{(\\alpha + \\beta)^{\\overline{n}}}","title":"add constant"},{"location":"models/polya_urn/#c-0c-0","text":"X_n\\sim \\text{Bin}(n,p) X_n\\sim \\text{Bin}(n,p)","title":"c = 0c = 0"},{"location":"models/polya_urn/#c-1c-1","text":"X_n\\sim \\text{Hypergeometric}(r+b, r, n) X_n\\sim \\text{Hypergeometric}(r+b, r, n)","title":"c = -1c = -1"},{"location":"models/polya_urn/#c-geq-1c-geq-1","text":"X_n\\sim \\text{Beta-binomial}(n,\\alpha,\\beta) X_n\\sim \\text{Beta-binomial}(n,\\alpha,\\beta)","title":"c \\geq 1c \\geq 1"},{"location":"models/polya_urn/#proof","text":"\\begin{align} \\dfrac{ \\alpha^{\\overline{k}} \\beta^{\\overline{n-k}}}{(\\alpha + \\beta)^{\\overline{n}}} &= \\dfrac{\\Gamma(\\alpha+k)/\\Gamma(\\alpha) \\cdot \\Gamma(\\beta+n-k)/\\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta+n)/\\Gamma(\\alpha+\\beta)} \\\\\\\\ &= \\dfrac{B(k+\\alpha,n-k+\\beta)}{B(\\alpha,\\beta)} \\end{align} \\begin{align} \\dfrac{ \\alpha^{\\overline{k}} \\beta^{\\overline{n-k}}}{(\\alpha + \\beta)^{\\overline{n}}} &= \\dfrac{\\Gamma(\\alpha+k)/\\Gamma(\\alpha) \\cdot \\Gamma(\\beta+n-k)/\\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta+n)/\\Gamma(\\alpha+\\beta)} \\\\\\\\ &= \\dfrac{B(k+\\alpha,n-k+\\beta)}{B(\\alpha,\\beta)} \\end{align} \\square \\square","title":"Proof"},{"location":"models/polya_urn/#limit","text":"M_\\infty \\sim \\text{Beta}(\\alpha,\\beta) M_\\infty \\sim \\text{Beta}(\\alpha,\\beta)","title":"limit"},{"location":"models/polya_urn/#proof_1","text":"\\begin{align} P(X_n=k) &= \\dfrac{\\Gamma(n+1)}{\\Gamma(k+1)\\Gamma(n-k+1)}\\dfrac{B(k+\\alpha,n-k+\\beta)}{B(\\alpha,\\beta)} \\\\\\\\ &= \\dfrac{1}{B(\\alpha,\\beta)} \\dfrac{k^{(\\alpha-1)} (n-k)^{(\\beta-1)}}{n^{(\\alpha+\\beta-1)}} \\end{align} \\begin{align} P(X_n=k) &= \\dfrac{\\Gamma(n+1)}{\\Gamma(k+1)\\Gamma(n-k+1)}\\dfrac{B(k+\\alpha,n-k+\\beta)}{B(\\alpha,\\beta)} \\\\\\\\ &= \\dfrac{1}{B(\\alpha,\\beta)} \\dfrac{k^{(\\alpha-1)} (n-k)^{(\\beta-1)}}{n^{(\\alpha+\\beta-1)}} \\end{align} note k^{(a)}\\rightarrow k^a k^{(a)}\\rightarrow k^a as k\\rightarrow\\infty k\\rightarrow\\infty , thus dP = \\dfrac{1}{B(\\alpha,\\beta)} x^{\\alpha-1}(1-x)^{\\beta-1}dx dP = \\dfrac{1}{B(\\alpha,\\beta)} x^{\\alpha-1}(1-x)^{\\beta-1}dx \\square \\square","title":"proof"},{"location":"models/polya_urn/#uniform","text":"In particular, \\alpha=\\beta=1 \\alpha=\\beta=1 , then M_\\infty\\sim U(0,1] M_\\infty\\sim U(0,1] . Recall Doob's maximal inequality, that P(\\sup M_n \\geq 3/4) \\leq 2/3 P(\\sup M_n \\geq 3/4) \\leq 2/3","title":"uniform"},{"location":"models/polya_urn/#bernard-friedmans-urn","text":"Add additional d_k d_k balls of opposite color. If c_k,d_k c_k,d_k uniformly bounded, r+b>0 r+b>0 , then M_n \\xrightarrow{a.s.}\\dfrac{1}{2} M_n \\xrightarrow{a.s.}\\dfrac{1}{2}","title":"Bernard Friedman\u2019s urn"},{"location":"models/reflection/","text":"Symmetric random walk \u00b6 a>0 a>0 , P(\\max_{k\\leq n} S_k > a) \\leq 2 P(S_n > a) P(\\max_{k\\leq n} S_k > a) \\leq 2 P(S_n > a) Symmetric SRW \u00b6 i.e. p=\\frac{1}{2},\\xi\\in\\{1,-1\\}, a>0 p=\\frac{1}{2},\\xi\\in\\{1,-1\\}, a>0 . P(\\max_{k\\leq n} S_k \\geq a) = 2P(S_n\\geq a) - P(S_n=a) P(\\max_{k\\leq n} S_k \\geq a) = 2P(S_n\\geq a) - P(S_n=a)","title":"Reflection principle"},{"location":"models/reflection/#symmetric-random-walk","text":"a>0 a>0 , P(\\max_{k\\leq n} S_k > a) \\leq 2 P(S_n > a) P(\\max_{k\\leq n} S_k > a) \\leq 2 P(S_n > a)","title":"Symmetric random walk"},{"location":"models/reflection/#symmetric-srw","text":"i.e. p=\\frac{1}{2},\\xi\\in\\{1,-1\\}, a>0 p=\\frac{1}{2},\\xi\\in\\{1,-1\\}, a>0 . P(\\max_{k\\leq n} S_k \\geq a) = 2P(S_n\\geq a) - P(S_n=a) P(\\max_{k\\leq n} S_k \\geq a) = 2P(S_n\\geq a) - P(S_n=a)","title":"Symmetric SRW"}]}